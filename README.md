# Daily Papers

## Abstract
Daily Papers is an automated literature aggregation pipeline that collects, normalizes, and publishes up-to-date research digests for configurable topics. It queries arXiv and, optionally, CrossRef, OpenAlex, Semantic Scholar, IEEE Xplore, DVCon proceedings, and the ACM Digital Library, then consolidates the latest results into a single Markdown feed that is easy to browse and index by search engines.

## Overview
The project automatically fetches the latest papers from arXiv and optionally from CrossRef, OpenAlex, Semantic Scholar, IEEE, DVCon proceedings, and ACM Digital Library based on configurable keywords (for example, digital/UVM verification or other topics).

The subheadings in the README file represent the search keywords (topics).

Only the most recent articles for each keyword are retained, up to a maximum of 100 papers.

You can click the 'Watch' button to receive daily email notifications.

Last update: 2026-02-12

## verification
### arXiv
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[MEVER: Multi-Modal and Explainable Claim Verification with Graph-based Evidence Retrieval](https://arxiv.org/abs/2602.10023v1)** | 2026-02-10 | <details><summary>Show</summary><p>Verifying the truthfulness of claims usually requires joint multi-modal reasoning over both textual and visual evidence, such as analyzing both textual caption and chart image for claim verification. In addition, to make the reasoning process transparent, a textual explanation is necessary to justify the verification result. However, most claim verification works mainly focus on the reasoning over textual evidence only or ignore the explainability, resulting in inaccurate and unconvincing verification. To address this problem, we propose a novel model that jointly achieves evidence retrieval, multi-modal claim verification, and explanation generation. For evidence retrieval, we construct a two-layer multi-modal graph for claims and evidence, where we design image-to-text and text-to-image reasoning for multi-modal retrieval. For claim verification, we propose token- and evidence-level fusion to integrate claim and evidence embeddings for multi-modal verification. For explanation generation, we introduce multi-modal Fusion-in-Decoder for explainability. Finally, since almost all the datasets are in general domain, we create a scientific dataset, AIChartClaim, in AI domain to complement claim verification community. Experiments show the strength of our model.</p></details> | Accepted to EACL-26 |
| **[X-Mark: Saliency-Guided Robust Dataset Ownership Verification for Medical Imaging](https://arxiv.org/abs/2602.09284v1)** | 2026-02-10 | <details><summary>Show</summary><p>High-quality medical imaging datasets are essential for training deep learning models, but their unauthorized use raises serious copyright and ethical concerns. Medical imaging presents a unique challenge for existing dataset ownership verification methods designed for natural images, as static watermark patterns generated in fixed-scale images scale poorly dynamic and high-resolution scans with limited visual diversity and subtle anatomical structures, while preserving diagnostic quality. In this paper, we propose X-Mark, a sample-specific clean-label watermarking method for chest x-ray copyright protection. Specifically, X-Mark uses a conditional U-Net to generate unique perturbations within salient regions of each sample. We design a multi-component training objective to ensure watermark efficacy, robustness against dynamic scaling processes while preserving diagnostic quality and visual-distinguishability. We incorporate Laplacian regularization into our training objective to penalize high-frequency perturbations and achieve watermark scale-invariance. Ownership verification is performed in a black-box setting to detect characteristic behaviors in suspicious models. Extensive experiments on CheXpert verify the effectiveness of X-Mark, achieving WSR of 100% and reducing probability of false positives in Ind-M scenario by 12%, while demonstrating resistance to potential adaptive attacks.</p></details> |  |
| **[Scalable Formal Verification via Autoencoder Latent Space Abstraction](https://arxiv.org/abs/2512.13593v3)** | 2026-02-09 | <details><summary>Show</summary><p>Finite Abstraction methods provide a powerful formal framework for proving that systems satisfy their specifications. However, these techniques face scalability challenges for high-dimensional systems, as they rely on state-space discretization which grows exponentially with dimension. Learning-based approaches to dimensionality reduction, utilizing neural networks and autoencoders, have shown great potential to alleviate this problem. However, ensuring the correctness of the resulting verification results remains an open question. In this work, we provide a formal approach to reduce the dimensionality of systems via convex autoencoders and learn the dynamics in the latent space through a kernel-based method. We then construct a finite abstraction from the learned model in the latent space and guarantee that the abstraction contains the true behaviors of the original system. We show that the verification results in the latent space can be mapped back to the original system. Finally, we demonstrate the effectiveness of our approach on multiple systems, including a 26D system controlled by a neural network, showing significant scalability improvements without loss of rigor.</p></details> | <details><summary>14 pa...</summary><p>14 pages, 7 figures, under review</p></details> |
| **[Restricted Receptive Fields for Face Verification](https://arxiv.org/abs/2510.10753v2)** | 2026-02-09 | <details><summary>Show</summary><p>Understanding how deep neural networks make decisions is crucial for analyzing their behavior and diagnosing failure cases. In computer vision, a common approach to improve interpretability is to assign importance to individual pixels using post-hoc methods. Although they are widely used to explain black-box models, their fidelity to the model's actual reasoning is uncertain due to the lack of reliable evaluation metrics. This limitation motivates an alternative approach, which is to design models whose decision processes are inherently interpretable. To this end, we propose a face similarity metric that breaks down global similarity into contributions from restricted receptive fields. Our method defines the similarity between two face images as the sum of patch-level similarity scores, providing a locally additive explanation without relying on post-hoc analysis. We show that the proposed approach achieves competitive verification performance even with patches as small as 28x28 within 112x112 face images, and surpasses state-of-the-art methods when using 56x56 patches.</p></details> |  |
| **[Out of the Shadows: Exploring a Latent Space for Neural Network Verification](https://arxiv.org/abs/2505.17854v3)** | 2026-02-09 | <details><summary>Show</summary><p>Neural networks are ubiquitous. However, they are often sensitive to small input changes. Hence, to prevent unexpected behavior in safety-critical applications, their formal verification -- a notoriously hard problem -- is necessary. Many state-of-the-art verification algorithms use reachability analysis or abstract interpretation to enclose the set of possible outputs of a neural network. Often, the verification is inconclusive due to the conservatism of the enclosure. To address this problem, we propose a novel specification-driven input refinement procedure, i.e., we iteratively enclose the preimage of a neural network for all unsafe outputs to reduce the set of possible inputs to only enclose the unsafe ones. For that, we transfer output specifications to the input space by exploiting a latent space, which is an artifact of the propagation of a projection-based set representation through a neural network. A projection-based set representation, e.g., a zonotope, is a "shadow" of a higher-dimensional set -- a latent space -- that does not change during a set propagation through a neural network. Hence, the input set and the output enclosure are "shadows" of the same latent space that we can use to transfer constraints. We present an efficient verification tool for neural networks that uses our iterative refinement to significantly reduce the number of subproblems in a branch-and-bound procedure. Using zonotopes as a set representation, unlike many other state-of-the-art approaches, our approach can be realized by only using matrix operations, which enables a significant speed-up through efficient GPU acceleration. We demonstrate that our tool achieves competitive performance compared to the top-ranking tools of the international neural network verification competition.</p></details> | <details><summary>Accep...</summary><p>Accepted at the 14th International Conference on Learning Representations (ICLR 2026)</p></details> |
| **[Craig Interpolation in Program Verification](https://arxiv.org/abs/2602.08532v1)** | 2026-02-09 | <details><summary>Show</summary><p>Craig interpolation is used in program verification for automating key tasks such as the inference of loop invariants and the computation of program abstractions. This chapter covers some of the most important techniques that have been developed in this context over the last years, focusing on two aspects: the derivation of Craig interpolants modulo the theories and data types used in verification and the basic design of verification algorithms applying interpolation.</p></details> | <details><summary>The a...</summary><p>The article will appear in Balder ten Cate, Jean Christoph Jung, Patrick Koopmann, Christoph Wernhard and Frank Wolter, editors. Theory and Applications of Craig Interpolation. Ubiquity Press, 2026</p></details> |
| **[Towards Real-World Industrial-Scale Verification: LLM-Driven Theorem Proving on seL4](https://arxiv.org/abs/2602.08384v1)** | 2026-02-09 | <details><summary>Show</summary><p>Formal methods (FM) are reliable but costly to apply, often requiring years of expert effort in industrial-scale projects such as seL4, especially for theorem proving. Recent advances in large language models (LLMs) have made automated theorem proving increasingly feasible. However, most prior work focuses on mathematics-oriented benchmarks such as miniF2F, with limited evaluation on real-world verification projects. The few studies that consider industrial-scale verification mostly rely on closed-source models with hundreds of billions of parameters, which cannot be locally deployed and incur substantial usage costs. In this paper, we propose AutoReal, an LLM-driven theorem proving method for real-world industrial-scale systems with support for lightweight local deployment. We evaluate AutoReal on the seL4-Isabelle verification project as a representative and challenging case study. AutoReal incorporates two key improvements: (1) chain-of-thought (CoT)-based proof training, which teaches the LLM the reasoning behind proof steps and enables step-wise explanations alongside proofs, and (2) context augmentation, which leverages proof context from the project to enhance LLM-driven proving. Based on the AutoReal methodology, we fine-tune a base model to obtain AutoReal-Prover, a compact 7B-scale prover for industrial-scale theorem proving. AutoReal-Prover achieves a 51.67% proof success rate on 660 theorems from seL4-designated Important Theories across all 10 seL4 proof categories, substantially outperforming prior attempts on seL4 (27.06%). To evaluate generalization, we further apply AutoReal-Prover to three security-related projects from the Archive of Formal Proofs (AFP), covering all 451 theorems and achieving a proof success rate of 53.88%. Overall, this work advances the application of LLM-driven theorem proving in real-world industrial-scale verification.</p></details> |  |
| **[Reimagining Legal Fact Verification with GenAI: Toward Effective Human-AI Collaboration](https://arxiv.org/abs/2602.06305v2)** | 2026-02-09 | <details><summary>Show</summary><p>Fact verification is a critical yet underexplored component of non-litigation legal practice. While existing research has examined automation in legal workflow and human-AI collaboration in high-stakes domains, little is known about how GenAI can support fact verification, a task that demands prudent judgment and strict accountability. To address this, we conducted semi-structured interviews with 18 lawyers to understand their current verification practices, attitudes toward GenAI adoption, and expectations for future systems. We found that while lawyers use GenAI for low-risk tasks like drafting and language optimization, concerns over accuracy, confidentiality, and liability are currently limiting its adoption for fact verification. These concerns translate into core design requirements for AI systems that are trustworthy and accountable. Based on these, we contribute design insights for human-AI collaboration in legal fact verification, emphasizing the development of auditable systems that balance efficiency with professional judgment and uphold ethical and legal accountability in high-stakes practice.</p></details> | Accepted by CHI 2026 |
| **[SciClaimEval: Cross-modal Claim Verification in Scientific Papers](https://arxiv.org/abs/2602.07621v1)** | 2026-02-07 | <details><summary>Show</summary><p>We present SciClaimEval, a new scientific dataset for the claim verification task. Unlike existing resources, SciClaimEval features authentic claims, including refuted ones, directly extracted from published papers. To create refuted claims, we introduce a novel approach that modifies the supporting evidence (figures and tables), rather than altering the claims or relying on large language models (LLMs) to fabricate contradictions. The dataset provides cross-modal evidence with diverse representations: figures are available as images, while tables are provided in multiple formats, including images, LaTeX source, HTML, and JSON. SciClaimEval contains 1,664 annotated samples from 180 papers across three domains, machine learning, natural language processing, and medicine, validated through expert annotation. We benchmark 11 multimodal foundation models, both open-source and proprietary, across the dataset. Results show that figure-based verification remains particularly challenging for all models, as a substantial performance gap remains between the best system and human baseline.</p></details> | <details><summary>12 pa...</summary><p>12 pages; data is available at https://sciclaimeval.github.io/</p></details> |
| **[Combining Tests and Proofs for Better Software Verification](https://arxiv.org/abs/2601.16239v2)** | 2026-02-07 | <details><summary>Show</summary><p>Test or prove? These two approaches to software verification have long been presented as opposites. One is dynamic, the other static: a test executes the program, a proof only analyzes the program text. A different perspective is emerging, in which testing and proving are complementary rather than competing techniques for producing software of verified quality. Work performed over the past few years and reviewed here develops this complementarity by taking advantage of Design by Contract, as available in Eiffel, and exploiting a feature of modern program-proving tools based on ``Satisfiability Modulo Theories'' (SMT): counterexample generation. A counterexample is an input combination that makes the program fail. If we are trying to prove a program correct, we hope not to find any. One can, however, apply counterexample generation to incorrect programs, as a tool for automatic test generation. We can also introduce faults into a correct program and turn the counterexamples into an automatically generated regression test suite with full coverage. Additionally, we can use these mechanisms to help produce program fixes for incorrect programs, with a guarantee that the fixes are correct. All three applications, leveraging on the mechanisms of Eiffel and Design by Contract, hold significant promise to address some of the challenges of program testing, software maintenance and Automatic Program Repair.</p></details> |  |
| **[Zero-Trust Runtime Verification for Agentic Payment Protocols: Mitigating Replay and Context-Binding Failures in AP2](https://arxiv.org/abs/2602.06345v1)** | 2026-02-06 | <details><summary>Show</summary><p>The deployment of autonomous AI agents capable of executing commercial transactions has motivated the adoption of mandate-based payment authorization protocols, including the Universal Commerce Protocol (UCP) and the Agent Payments Protocol (AP2). These protocols replace interactive, session-based authorization with cryptographically issued mandates, enabling asynchronous and autonomous execution. While AP2 provides specification-level guarantees through signature verification, explicit binding, and expiration semantics, real-world agentic execution introduces runtime behaviors such as retries, concurrency, and orchestration that challenge implicit assumptions about mandate usage. In this work, we present a security analysis of the AP2 mandate lifecycle and identify enforcement gaps that arise during runtime in agent-based payment systems. We propose a zero-trust runtime verification framework that enforces explicit context binding and consume-once mandate semantics using dynamically generated, time-bound nonces, ensuring that authorization decisions are evaluated at execution time rather than assumed from static issuance properties. Through simulation-based evaluation under high concurrency, we show that context-aware binding and consume-once enforcement address distinct and complementary attack classes, and that both are required to prevent replay and context-redirect attacks. The proposed framework mitigates all evaluated attacks while maintaining stable verification latency of approximately 3.8~ms at throughput levels up to 10{,}000 transactions per second. We further demonstrate that the required runtime state is bounded by peak concurrency rather than cumulative transaction history, indicating that robust runtime security for agentic payment execution can be achieved with minimal and predictable overhead.</p></details> |  |
| **[Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding](https://arxiv.org/abs/2602.06161v1)** | 2026-02-05 | <details><summary>Show</summary><p>Parallel diffusion decoding can accelerate diffusion language model inference by unmasking multiple tokens per step, but aggressive parallelism often harms quality. Revocable decoding mitigates this by rechecking earlier tokens, yet we observe that existing verification schemes frequently trigger flip-flop oscillations, where tokens are remasked and later restored unchanged. This behaviour slows inference in two ways: remasking verified positions weakens the conditioning context for parallel drafting, and repeated remask cycles consume the revision budget with little net progress. We propose COVER (Cache Override Verification for Efficient Revision), which performs leave-one-out verification and stable drafting within a single forward pass. COVER constructs two attention views via KV cache override: selected seeds are masked for verification, while their cached key value states are injected for all other queries to preserve contextual information, with a closed form diagonal correction preventing self leakage at the seed positions. COVER further prioritises seeds using a stability aware score that balances uncertainty, downstream influence, and cache drift, and it adapts the number of verified seeds per step. Across benchmarks, COVER markedly reduces unnecessary revisions and yields faster decoding while preserving output quality.</p></details> |  |
| **[Algebraic Robustness Verification of Neural Networks](https://arxiv.org/abs/2602.06105v1)** | 2026-02-05 | <details><summary>Show</summary><p>We formulate formal robustness verification of neural networks as an algebraic optimization problem. We leverage the Euclidean Distance (ED) degree, which is the generic number of complex critical points of the distance minimization problem to a classifier's decision boundary, as an architecture-dependent measure of the intrinsic complexity of robustness verification. To make this notion operational, we define the associated ED discriminant, which characterizes input points at which the number of real critical points changes, distinguishing test instances that are easier or harder to verify. We provide an explicit algorithm for computing this discriminant. We further introduce the parameter discriminant of a neural network, identifying parameters where the ED degree drops and the decision boundary exhibits reduced algebraic complexity. We derive closed-form expressions for the ED degree for several classes of neural architectures, as well as formulas for the expected number of real critical points in the infinite-width limit. Finally, we present an exact robustness certification algorithm based on numerical homotopy continuation, establishing a concrete link between metric algebraic geometry and neural network verification.</p></details> |  |
| **[STELLAR: Structure-guided LLM Assertion Retrieval and Generation for Formal Verification](https://arxiv.org/abs/2601.19903v2)** | 2026-02-05 | <details><summary>Show</summary><p>Formal Verification (FV) relies on high-quality SystemVerilog Assertions (SVAs), but the manual writing process is slow and error-prone. Existing LLM-based approaches either generate assertions from scratch or ignore structural patterns in hardware designs and expert-crafted assertions. This paper presents STELLAR, the first framework that guides LLM-based SVA generation with structural similarity. STELLAR represents RTL blocks as AST structural fingerprints, retrieves structurally relevant (RTL, SVA) pairs from a knowledge base, and integrates them into structure-guided prompts. Experiments show that STELLAR achieves superior syntax correctness, stylistic alignment, and functional correctness, highlighting structure-aware retrieval as a promising direction for industrial FV.</p></details> | 7 pages, 6 figures |
| **[Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification](https://arxiv.org/abs/2602.05723v1)** | 2026-02-05 | <details><summary>Show</summary><p>In financial Retrieval-Augmented Generation (RAG) systems, models frequently rely on retrieved documents to generate accurate responses due to the time-sensitive nature of the financial domain. While retrieved documents help address knowledge gaps, model-generated responses still suffer from hallucinations that contradict the retrieved information. To mitigate this inconsistency, we propose a Reinforcement Learning framework enhanced with Fine-grained Knowledge Verification (RLFKV). Our method decomposes financial responses into atomic knowledge units and assesses the correctness of each unit to compute the fine-grained faithful reward. This reward offers more precise optimization signals, thereby improving alignment with the retrieved documents. Additionally, to prevent reward hacking (e.g., overly concise replies), we incorporate an informativeness reward that encourages the policy model to retain at least as many knowledge units as the base model. Experiments conducted on the public Financial Data Description (FDD) task and our newly proposed FDD-ANT dataset demonstrate consistent improvements, confirming the effectiveness of our approach.</p></details> | <details><summary>accep...</summary><p>accepted by ICASSP 2026</p></details> |
| **[Abstract Framework for All-Path Reachability Analysis toward Safety and Liveness Verification (Full Version)](https://arxiv.org/abs/2602.04641v2)** | 2026-02-05 | <details><summary>Show</summary><p>An all-path reachability (APR) predicate over an object set is a pair of a source set and a target set, which are subsets of the object set. APR predicates have been defined for abstract reduction systems (ARSs) and then extended to logically constrained term rewrite systems (LCTRSs) as pairs of constrained terms that represent sets of terms modeling configurations, states, etc. An APR predicate is said to be partially (or demonically) valid w.r.t. a rewrite system if every finite maximal reduction sequence of the system starting from any element in the source set includes an element in the target set. Partial validity of APR predicates w.r.t. ARSs is defined by means of two inference rules, which can be considered a proof system to construct (possibly infinite) derivation trees for partial validity. On the other hand, a proof system for LCTRSs consists of four inference rules, leaving a gap between the inference rules for ARSs and LCTRSs. In this paper, we revisit the framework for APR analysis and adapt it to verification of not only safety but also liveness properties. To this end, we first reformulate an abstract framework for partial validity w.r.t. ARSs so that there is a one-to-one correspondence between the inference rules for partial validity w.r.t. ARSs and LCTRSs. Secondly, we show how to apply APR analysis to safety verification. Thirdly, to apply APR analysis to liveness verification, we introduce a novel stronger validity of APR predicates, called total validity, which requires not only finite but also infinite execution paths to reach target sets. Finally, for a partially valid APR predicate with a cyclic-proof tree, we show a necessary and sufficient condition for the tree to ensure total validity. The condition implies that if there exists a cyclic-proof tree for an APR predicate, the proof graph of which is acyclic, then the APR predicate is totally valid.</p></details> | <details><summary>21 pa...</summary><p>21 pages, full version of a submission to FSCD 2026</p></details> |
| **[Statistical Verification of Medium-Access Parameterization for Power-Grid Edge Ad Hoc Sensor Networks](https://arxiv.org/abs/2602.05510v1)** | 2026-02-05 | <details><summary>Show</summary><p>The widespread deployment of power grid ad hoc sensor networks based on IEEE 802.15.4 raises reliability challenges when nodes selfishly adapt CSMA/CA parameters to maximize individual performance. Such behavior degrades reliability, energy efficiency, and compliance with strict grid constraints. Existing analytical and simulation approaches often fail to rigorously evaluate configurations under asynchronous, event-driven, and resource-limited conditions. We develop a verification framework that integrates stochastic timed hybrid automata with statistical model checking (SMC) with confidence bounds to formally assess CSMA/CA parameterizations under grid workloads. By encoding node- and system-level objectives in temporal logic and automating protocol screening via large-scale statistical evaluation, the method certifies Nash equilibrium strategies that remain robust to unilateral deviations. In a substation-scale scenario, the certified equilibrium improves utility from 0.862 to 0.914 and raises the delivery ratio from 89.5% to 93.2% when compared with an aggressive tuning baseline. Against a delivery-oriented baseline, it reduces mean per-cycle energy from 152.8 mJ to 149.2 mJ while maintaining comparable delivery performance. Certified configurations satisfy latency, reliability, and energy constraints with robustness coefficients above 0.97 and utility above 0.91.</p></details> |  |
| **[E-Globe: Scalable $ε$-Global Verification of Neural Networks via Tight Upper Bounds and Pattern-Aware Branching](https://arxiv.org/abs/2602.05068v1)** | 2026-02-04 | <details><summary>Show</summary><p>Neural networks achieve strong empirical performance, but robustness concerns still hinder deployment in safety-critical applications. Formal verification provides robustness guarantees, but current methods face a scalability-completeness trade-off. We propose a hybrid verifier in a branch-and-bound (BaB) framework that efficiently tightens both upper and lower bounds until an $ε-$global optimum is reached or early stop is triggered. The key is an exact nonlinear program with complementarity constraints (NLP-CC) for upper bounding that preserves the ReLU input-output graph, so any feasible solution yields a valid counterexample and enables rapid pruning of unsafe subproblems. We further accelerate verification with (i) warm-started NLP solves requiring minimal constraint-matrix updates and (ii) pattern-aligned strong branching that prioritizes splits most effective at tightening relaxations. We also provide conditions under which NLP-CC upper bounds are tight. Experiments on MNIST and CIFAR-10 show markedly tighter upper bounds than PGD across perturbation radii spanning up to three orders of magnitude, fast per-node solves in practice, and substantial end-to-end speedups over MIP-based verification, amplified by warm-starting, GPU batching, and pattern-aligned branching.</p></details> | 16 pages, 10 figures |
| **[When Code Becomes Abundant: Redefining Software Engineering Around Orchestration and Verification](https://arxiv.org/abs/2602.04830v1)** | 2026-02-04 | <details><summary>Show</summary><p>Software Engineering (SE) faces simultaneous pressure from AI automation (reducing code production costs) and hardware-energy constraints (amplifying failure costs). We position that SE must redefine itself around human discernment-intent articulation, architectural control, and verification-rather than code construction. This shift introduces accountability collapse as a central risk and requires fundamental changes to research priorities, educational curricula, and industrial practices. We argue that Software Engineering, as traditionally defined around code construction and process management, is no longer sufficient. Instead, the discipline must be redefined around intent articulation, architectural control, and systematic verification. This redefinition shifts Software Engineering from a production-oriented field to one centered on human judgment under automation, with profound implications for research, practice, and education.</p></details> | <details><summary>Accep...</summary><p>Accepted to 2026 IEEE/ACM 48th International Conference on Software Engineering: Future of Software Engineering</p></details> |
| **[Verification and Identification in ECG biometric on large-scale](https://arxiv.org/abs/2602.02776v2)** | 2026-02-04 | <details><summary>Show</summary><p>This work studies electrocardiogram (ECG) biometrics at large scale, directly addressing a critical gap in the literature: the scarcity of large-scale evaluations with operational metrics and protocols that enable meaningful standardization and comparison across studies. We show that identity information is already present in tabular representations (fiducial features): even a simple MLP-based embedding network yields non-trivial performance, establishing a strong baseline before waveform modeling. We then adopt embedding-based deep learning models (ArcFace), first on features and then on ECG waveforms, showing a clear performance jump when moving from tabular inputs to waveforms, and a further gain with larger training sets and consistent normalization across train/val/test. On a large-scale test set, verification achieves high TAR at strict FAR thresholds (TAR=0.908 @ FAR=1e-3; TAR=0.820 @ FAR=1e-4) with EER=2.53\% (all-vs-all); closed-set identification yields Rank@1=0.812 and Rank@10=0.910. In open-set, a two-stage pipeline (top-$K$ shortlist on embeddings + re-ranking) reaches DIR@FAR up to 0.976 at FAR=1e-3 and 1e-4. Overall, the results show that ECG carries a measurable individual signature and that large-scale testing is essential to obtain realistic, comparable metrics. The study provides an operationally grounded benchmark that helps standardize evaluation across protocols.</p></details> |  |
| **[Noise-Conditioned Mixture-of-Experts Framework for Robust Speaker Verification](https://arxiv.org/abs/2510.18533v2)** | 2026-02-04 | <details><summary>Show</summary><p>Robust speaker verification under noisy conditions remains an open challenge. Conventional deep learning methods learn a robust unified speaker representation space against diverse background noise and achieve significant improvement. In contrast, this paper presents a noise-conditioned mixture-ofexperts framework that decomposes the feature space into specialized noise-aware subspaces for speaker verification. Specifically, we propose a noise-conditioned expert routing mechanism, a universal model based expert specialization strategy, and an SNR-decaying curriculum learning protocol, collectively improving model robustness and generalization under diverse noise conditions. The proposed method can automatically route inputs to expert networks based on noise information derived from the inputs, where each expert targets distinct noise characteristics while preserving speaker identity information. Comprehensive experiments demonstrate consistent superiority over baselines, confirming that explicit noise-dependent feature modeling significantly enhances robustness without sacrificing verification accuracy.</p></details> |  |
| **[Cascading Robustness Verification: Toward Efficient Model-Agnostic Certification](https://arxiv.org/abs/2602.04236v1)** | 2026-02-04 | <details><summary>Show</summary><p>Certifying neural network robustness against adversarial examples is challenging, as formal guarantees often require solving non-convex problems. Hence, incomplete verifiers are widely used because they scale efficiently and substantially reduce the cost of robustness verification compared to complete methods. However, relying on a single verifier can underestimate robustness because of loose approximations or misalignment with training methods. In this work, we propose Cascading Robustness Verification (CRV), which goes beyond an engineering improvement by exposing fundamental limitations of existing robustness metric and introducing a framework that enhances both reliability and efficiency. CRV is a model-agnostic verifier, meaning that its robustness guarantees are independent of the model's training process. The key insight behind the CRV framework is that, when using multiple verification methods, an input is certifiably robust if at least one method certifies it as robust. Rather than relying solely on a single verifier with a fixed constraint set, CRV progressively applies multiple verifiers to balance the tightness of the bound and computational cost. Starting with the least expensive method, CRV halts as soon as an input is certified as robust; otherwise, it proceeds to more expensive methods. For computationally expensive methods, we introduce a Stepwise Relaxation Algorithm (SR) that incrementally adds constraints and checks for certification at each step, thereby avoiding unnecessary computation. Our theoretical analysis demonstrates that CRV achieves equal or higher verified accuracy compared to powerful but computationally expensive incomplete verifiers in the cascade, while significantly reducing verification overhead. Empirical results confirm that CRV certifies at least as many inputs as benchmark approaches, while improving runtime efficiency by up to ~90%.</p></details> |  |
| **[EVE: Efficient Verification of Data Erasure through Customized Perturbation in Approximate Unlearning](https://arxiv.org/abs/2602.03567v1)** | 2026-02-03 | <details><summary>Show</summary><p>Verifying whether the machine unlearning process has been properly executed is critical but remains underexplored. Some existing approaches propose unlearning verification methods based on backdooring techniques. However, these methods typically require participation in the model's initial training phase to backdoor the model for later verification, which is inefficient and impractical. In this paper, we propose an efficient verification of erasure method (EVE) for verifying machine unlearning without requiring involvement in the model's initial training process. The core idea is to perturb the unlearning data to ensure the model prediction of the specified samples will change before and after unlearning with perturbed data. The unlearning users can leverage the observation of the changes as a verification signal. Specifically, the perturbations are designed with two key objectives: ensuring the unlearning effect and altering the unlearned model's prediction of target samples. We formalize the perturbation generation as an adversarial optimization problem, solving it by aligning the unlearning gradient with the gradient of boundary change for target samples. We conducted extensive experiments, and the results show that EVE can verify machine unlearning without involving the model's initial training process, unlike backdoor-based methods. Moreover, EVE significantly outperforms state-of-the-art unlearning verification methods, offering significant speedup in efficiency while enhancing verification accuracy. The source code of EVE is released at \uline{https://anonymous.4open.science/r/EVE-C143}, providing a novel tool for verification of machine unlearning.</p></details> |  |
| **[Self-Verification Dilemma: Experience-Driven Suppression of Overused Checking in LLM Reasoning](https://arxiv.org/abs/2602.03485v1)** | 2026-02-03 | <details><summary>Show</summary><p>Large Reasoning Models (LRMs) achieve strong performance by generating long reasoning traces with reflection. Through a large-scale empirical analysis, we find that a substantial fraction of reflective steps consist of self-verification (recheck) that repeatedly confirm intermediate results. These rechecks occur frequently across models and benchmarks, yet the vast majority are confirmatory rather than corrective, rarely identifying errors and altering reasoning outcomes. This reveals a mismatch between how often self-verification is activated and how often it is actually useful. Motivated by this, we propose a novel, experience-driven test-time framework that reduces the overused verification. Our method detects the activation of recheck behavior, consults an offline experience pool of past verification outcomes, and estimates whether a recheck is likely unnecessary via efficient retrieval. When historical experience suggests unnecessary, a suppression signal redirects the model to proceed. Across multiple model and benchmarks, our approach reduces token usage up to 20.3% while maintaining the accuracy, and in some datasets even yields accuracy improvements.</p></details> | 19 pages, 8 figures |
| **[TurboFuzz: FPGA Accelerated Hardware Fuzzing for Processor Agile Verification](https://arxiv.org/abs/2509.10400v2)** | 2026-02-03 | <details><summary>Show</summary><p>Verification is a critical process for ensuring the correctness of modern processors. The increasing complexity of processor designs and the emergence of new instruction set architectures (ISAs) like RISC-V have created demands for more agile and efficient verification methodologies, particularly regarding verification efficiency and faster coverage convergence. While simulation-based approaches now attempt to incorporate advanced software testing techniques such as fuzzing to improve coverage, they face significant limitations when applied to processor verification, notably poor performance and inadequate test case quality. Hardware-accelerated solutions using FPGA or ASIC platforms have tried to address these issues, yet they struggle with challenges including host-FPGA communication overhead, inefficient test pattern generation, and suboptimal implementation of the entire multi-step verification process. In this paper, we present TurboFuzz, an end-to-end hardware-accelerated verification framework that implements the entire Test Generation-Simulation-Coverage Feedback loop on a single FPGA for modern processor verification. TurboFuzz enhances test quality through optimized test case (seed) control flow, efficient inter-seed scheduling, and hybrid fuzzer integration, thereby improving coverage and execution efficiency. Additionally, it employs a feedback-driven generation mechanism to accelerate coverage convergence. Experimental results show that TurboFuzz achieves up to 2.23x more coverage collection than software-based fuzzers within the same time budget, and up to 571x performance speedup when detecting real-world issues, while maintaining full visibility and debugging capabilities with moderate area overhead.</p></details> |  |
| **[Adequately Tailoring Age Verification Regulations](https://arxiv.org/abs/2601.20241v2)** | 2026-02-03 | <details><summary>Show</summary><p>The Supreme Court decision in Free Speech Coalition v. Paxton upheld the constitutionality of Texas H.B. 1181, one of the most constitutionally vulnerable of these age verification laws, holding that it was subject to and satisfied intermediate scrutiny and the requirement that age verification regulations be "adequately tailored". However, the decision leaves unresolved practical challenges. What is the current state of age verification legislation in the United States? How can "adequate tailoring" be interpreted in a way that is accessible to non-legal experts, particularly those in technical and engineering domains? What age verification approaches are used today, what infrastructures and standards support them, and what tradeoffs do they introduce? This paper addresses those questions by proposing an analytical model to interpret "adequate tailoring" from multiple perspectives with associated governmental goals and interests, and by applying that model to evaluate both current state laws and widely used verification methods. This paper's major contributions include: (1) we mapped the current U.S. age-verification legislative landscape; (2) we introduce an analytical model to analyze "adequate tailoring" for age verification and potential application to other online regulatory policies; and (3) we analyze the main technical approaches to age verification, highlighting the practical challenges and tradeoffs from a technical perspective. Further, while we focus on U.S. State laws, the principles underlying our framework are applicable to age-verification debates and methods worldwide.</p></details> | <details><summary>This ...</summary><p>This paper is accepted by the ACM Symposium on Computer Science and Law (CS & Law 2026)</p></details> |
| **[Free Draft-and-Verification: Toward Lossless Parallel Decoding for Diffusion Large Language Models](https://arxiv.org/abs/2510.00294v3)** | 2026-02-03 | <details><summary>Show</summary><p>Diffusion Large Language Models (DLLMs) have emerged as a new paradigm of language modeling beyond autoregressive next-token prediction. Taking advantage of their inherent modeling foundations, DLLMs have the great potential of efficient inference with parallel decoding algorithms, which enable multi-token prediction. However, the high generation quality often requires the number of decoding steps equal to the sequence length, which performs a one-token-per-step decoding, and existing parallel decoding algorithms, which yield suboptimal decoding paths, bring inference speedup at the cost of non-negligible performance degradation. To overcome this challenge, we introduce Free Draft-and-Verification (FreeDave), a novel fast decoding algorithm tailored for DLLMs that achieves lossless parallel decoding without any model modification or extra modules. Specifically, we propose an algorithm of parallel-decoded candidate generation and verification, which is theoretically guaranteed to use the fewest model forward calls to reproduce the same sequence generated by one-token-per-step decoding. By extensive evaluations on math reasoning and code generation benchmarks across different DLLMs, FreeDave is proven to accelerate the inference up to $2.83\times$ without performance degradation.</p></details> |  |
| **[MAS-ProVe: Understanding the Process Verification of Multi-Agent Systems](https://arxiv.org/abs/2602.03053v1)** | 2026-02-03 | <details><summary>Show</summary><p>Multi-Agent Systems (MAS) built on Large Language Models (LLMs) often exhibit high variance in their reasoning trajectories. Process verification, which evaluates intermediate steps in trajectories, has shown promise in general reasoning settings, and has been suggested as a potential tool for guiding coordination of MAS; however, its actual effectiveness in MAS remains unclear. To fill this gap, we present MAS-ProVe, a systematic empirical study of process verification for multi-agent systems (MAS). Our study spans three verification paradigms (LLM-as-a-Judge, reward models, and process reward models), evaluated across two levels of verification granularity (agent-level and iteration-level). We further examine five representative verifiers and four context management strategies, and conduct experiments over six diverse MAS frameworks on multiple reasoning benchmarks. We find that process-level verification does not consistently improve performance and frequently exhibits high variance, highlighting the difficulty of reliably evaluating partial multi-agent trajectories. Among the methods studied, LLM-as-a-Judge generally outperforms reward-based approaches, with trained judges surpassing general-purpose LLMs. We further observe a small performance gap between LLMs acting as judges and as single agents, and identify a context-length-performance trade-off in verification. Overall, our results suggest that effective and robust process verification for MAS remains an open challenge, requiring further advances beyond current paradigms. Code is available at https://github.com/Wang-ML-Lab/MAS-ProVe.</p></details> | <details><summary>Prepr...</summary><p>Preprint; work in progress</p></details> |
| **[Provenance Verification of AI-Generated Images via a Perceptual Hash Registry Anchored on Blockchain](https://arxiv.org/abs/2602.02412v1)** | 2026-02-02 | <details><summary>Show</summary><p>The rapid advancement of artificial intelligence has made the generation of synthetic images widely accessible, increasing concerns related to misinformation, digital forgery, and content authenticity on large-scale online platforms. This paper proposes a blockchain-backed framework for verifying AI-generated images through a registry-based provenance mechanism. Each AI-generated image is assigned a digital fingerprint that preserves similarity using perceptual hashing and is registered at creation time by participating generation platforms. The hashes are stored on a hybrid on-chain/off-chain public blockchain using a Merkle Patricia Trie for tamper-resistant storage (on-chain) and a Burkhard-Keller tree (off-chain) to enable efficient similarity search over large image registries. Verification is performed when images are re-uploaded to digital platforms such as social media services, enabling identification of previously registered AI-generated images even after benign transformations or partial modifications. The proposed system does not aim to universally detect all synthetic images, but instead focuses on verifying the provenance of AI-generated content that has been registered at creation time. By design, this approach complements existing watermarking and learning-based detection methods, providing a platform-agnostic, tamper-proof mechanism for scalable content provenance and authenticity verification at the point of large-scale online distribution.</p></details> |  |
| **[MINIF2F-DAFNY: LLM-Guided Mathematical Theorem Proving via Auto-Active Verification](https://arxiv.org/abs/2512.10187v2)** | 2026-02-02 | <details><summary>Show</summary><p>LLMs excel at reasoning, but validating their steps remains challenging. Formal verification offers a solution through mechanically checkable proofs. Interactive theorem provers (ITPs) dominate mathematical reasoning but require detailed low-level proof steps, while auto-active verifiers offer automation but focus on software verification. Recent work has begun bridging this divide by evaluating LLMs for software verification in ITPs, but the complementary direction--LLMs for mathematical theorem proving in auto-active verifiers--remains unexplored. We present MINIF2F-DAFNY, the first translation of the widely-used mathematical benchmark miniF2F to an auto-active verifier: Dafny. We find that Dafny's automation alone solves 39-44% of problems with empty proofs, whereas many require substantial proof guidance in ITPs. For remaining problems, we evaluate 7 off-the-shelf LLMs, achieving 55.7% success with the best model (Claude Sonnet 4.5) using modest resources. These results demonstrate effective division of labor: LLMs provide high-level guidance while automation handles low-level details. Our benchmark can be found on GitHub at http://github.com/dafny-lang/miniF2F .</p></details> |  |
| **[Do I Really Know? Learning Factual Self-Verification for Hallucination Reduction](https://arxiv.org/abs/2602.02018v1)** | 2026-02-02 | <details><summary>Show</summary><p>Factual hallucination remains a central challenge for large language models (LLMs). Existing mitigation approaches primarily rely on either external post-hoc verification or mapping uncertainty directly to abstention during fine-tuning, often resulting in overly conservative behavior. We propose VeriFY, a training-time framework that teaches LLMs to reason about factual uncertainty through consistency-based self-verification. VeriFY augments training with structured verification traces that guide the model to produce an initial answer, generate and answer a probing verification query, issue a consistency judgment, and then decide whether to answer or abstain. To address the risk of reinforcing hallucinated content when training on augmented traces, we introduce a stage-level loss masking approach that excludes hallucinated answer stages from the training objective while preserving supervision over verification behavior. Across multiple model families and scales, VeriFY reduces factual hallucination rates by 9.7 to 53.3 percent, with only modest reductions in recall (0.4 to 5.7 percent), and generalizes across datasets when trained on a single source. The source code, training data, and trained model checkpoints will be released upon acceptance.</p></details> |  |
| **[Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models](https://arxiv.org/abs/2602.01842v1)** | 2026-02-02 | <details><summary>Show</summary><p>Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window, (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at https://github.com/viiika/Prism.</p></details> |  |
| **[Construction-Verification: A Benchmark for Applied Mathematics in Lean 4](https://arxiv.org/abs/2602.01291v1)** | 2026-02-01 | <details><summary>Show</summary><p>Recent advances in large language models have demonstrated impressive capabilities in mathematical formalization. However, existing benchmarks focus on logical verification of declarative propositions, often neglecting the task of explicitly synthesizing solutions. This limitation is particularly acute in applied mathematics domains, where the goal is frequently to derive concrete values or executable algorithms rather than solely proving theorems. To address this, we introduce a Lean 4 framework that enforces a construction-verification workflow, compelling the agent to define explicit solutions before proving their correctness. We curate a comprehensive benchmark AMBER (Applied Mathematics BEnchmark for Reasoning) spanning core domains of applied mathematics, including convex analysis, optimization, numerical algebra, and high-dimensional probability. Aside from theorem proving, our benchmark features complex tasks such as evaluation, algorithm design, and representation transformation. Experiments reveal that current models face significant difficulties with these constructive tasks. Notably, we observe that general-purpose reasoning models consistently outperform specialized theorem provers. We attribute this to a degradation of instruction following capabilities in specialized models. Fine-tuning on proof corpora appears to induce ``tactical overfitting", compromising the ability to adhere to complex constructive requirements, whereas general models retain the versatility needed for multi-task formal reasoning.</p></details> |  |
| **[PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length](https://arxiv.org/abs/2602.01274v1)** | 2026-02-01 | <details><summary>Show</summary><p>Speculative decoding (SD) is a powerful technique for accelerating the inference process of large language models (LLMs) without sacrificing accuracy. Typically, SD employs a small draft model to generate a fixed number of draft tokens, which are then verified in parallel by the target model. However, our experiments reveal that the optimal draft length varies significantly across different decoding steps. This variation suggests that using a fixed draft length limits the potential for further improvements in decoding speed. To address this challenge, we propose Pacer, a novel approach that dynamically controls draft length using a lightweight, trainable pre-verification layer. This layer pre-verifies draft tokens blockwise before they are sent to the target model, allowing the draft model to stop token generation if the blockwise pre-verification fails. We implement Pacer on multiple SD model pairs and evaluate its performance across various benchmarks. Our results demonstrate that Pacer achieves up to 2.66x Speedup over autoregressive decoding and consistently outperforms standard speculative decoding. Furthermore, when integrated with Ouroboros, Pacer attains up to 3.09x Speedup.</p></details> |  |
| **[Verification Required: The Impact of Information Credibility on AI Persuasion](https://arxiv.org/abs/2602.00970v1)** | 2026-02-01 | <details><summary>Show</summary><p>Agents powered by large language models (LLMs) are increasingly deployed in settings where communication shapes high-stakes decisions, making a principled understanding of strategic communication essential. Prior work largely studies either unverifiable cheap-talk or fully verifiable disclosure, failing to capture realistic domains in which information has probabilistic credibility. We introduce MixTalk, a strategic communication game for LLM-to-LLM interaction that models information credibility. In MixTalk, a sender agent strategically combines verifiable and unverifiable claims to communicate private information, while a receiver agent allocates a limited budget to costly verification and infers the underlying state from prior beliefs, claims, and verification outcomes. We evaluate state-of-the-art LLM agents in large-scale tournaments across three realistic deployment settings, revealing their strengths and limitations in reasoning about information credibility and the explicit behavior that shapes these interactions. Finally, we propose Tournament Oracle Policy Distillation (TOPD), an offline method that distills tournament oracle policy from interaction logs and deploys it in-context at inference time. Our results show that TOPD significantly improves receiver robustness to persuasion.</p></details> | 19 pages, 5 figures |
| **[Quokka: Accelerating Program Verification with LLMs via Invariant Synthesis](https://arxiv.org/abs/2509.21629v2)** | 2026-01-30 | <details><summary>Show</summary><p>Program verification relies on loop invariants, yet automatically discovering strong invariants remains a long-standing challenge. We investigate whether large language models (LLMs) can accelerate program verification by generating useful loop invariants. We introduce Quokka, a first-order and effective framework for LLM-based invariant synthesis that provides sound evaluation while achieving state-of-the-art speedup results. Unlike prior work that designs complex, highly customized algorithms, Quokka employs a simple and principled verification procedure. We construct a benchmark of 866 instances and evaluate 9 state-of-the-art LLMs across multiple model families. Our results show that Quokka consistently outperforms all prior LLM-based verifiers: achieving speedups of at least 1.2x on 81 instances compared to 39 instances for the previous best approach. We further demonstrate that supervised fine-tuning and Best-of-N sampling can yield measurable improvements in accelerating verification.</p></details> |  |
| **[TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification](https://arxiv.org/abs/2601.23180v1)** | 2026-01-30 | <details><summary>Show</summary><p>Inference efficiency in Large Language Models (LLMs) is fundamentally limited by their serial, autoregressive generation, especially as reasoning becomes a key capability and response sequences grow longer. Speculative decoding (SD) offers a powerful solution, providing significant speed-ups through its lightweight drafting and parallel verification mechanism. While existing work has nearly saturated improvements in draft effectiveness and efficiency, this paper advances SD from a new yet critical perspective: the verification cost. We propose TriSpec, a novel ternary SD framework that, at its core, introduces a lightweight proxy to significantly reduce computational cost by approving easily verifiable draft sequences and engaging the full target model only when encountering uncertain tokens. TriSpec can be integrated with state-of-the-art SD methods like EAGLE-3 to further reduce verification costs, achieving greater acceleration. Extensive experiments on the Qwen3 and DeepSeek-R1-Distill-Qwen/LLaMA families show that TriSpec achieves up to 35\% speedup over standard SD, with up to 50\% fewer target model invocations while maintaining comparable accuracy.</p></details> |  |
| **[Pushing the Boundaries of Natural Reasoning: Interleaved Bonus from Formal-Logic Verification](https://arxiv.org/abs/2601.22642v1)** | 2026-01-30 | <details><summary>Show</summary><p>Large Language Models (LLMs) show remarkable capabilities, yet their stochastic next-token prediction creates logical inconsistencies and reward hacking that formal symbolic systems avoid. To bridge this gap, we introduce a formal logic verification-guided framework that dynamically interleaves formal symbolic verification with the natural language generation process, providing real-time feedback to detect and rectify errors as they occur. Distinguished from previous neuro-symbolic methods limited by passive post-hoc validation, our approach actively penalizes intermediate fallacies during the reasoning chain. We operationalize this framework via a novel two-stage training pipeline that synergizes formal logic verification-guided supervised fine-tuning and policy optimization. Extensive evaluation on six benchmarks spanning mathematical, logical, and general reasoning demonstrates that our 7B and 14B models outperform state-of-the-art baselines by average margins of 10.4% and 14.2%, respectively. These results validate that formal verification can serve as a scalable mechanism to significantly push the performance boundaries of advanced LLM reasoning.</p></details> |  |
| **[Debating Truth: Debate-driven Claim Verification with Multiple Large Language Model Agents](https://arxiv.org/abs/2507.19090v3)** | 2026-01-30 | <details><summary>Show</summary><p>State-of-the-art single-agent claim verification methods struggle with complex claims that require nuanced analysis of multifaceted evidence. Inspired by real-world professional fact-checkers, we propose \textbf{DebateCV}, the first debate-driven claim verification framework powered by multiple LLM agents. In DebateCV, two \textit{Debaters} argue opposing stances to surface subtle errors in single-agent assessments. A decisive \textit{Moderator} is then required to weigh the evidential strength of conflicting arguments to deliver an accurate verdict. Yet, zero-shot Moderators are biased toward neutral judgments, and no datasets exist for training them. To bridge this gap, we propose \textbf{Debate-SFT}, a post-training framework that leverages synthetic data to enhance agents' ability to effectively adjudicate debates for claim verification. Results show that our methods surpass state-of-the-art non-debate approaches in both accuracy (across various evidence conditions) and justification quality.</p></details> | <details><summary>Accep...</summary><p>Accepted by the ACM Web Conference 2026 (WWW 2026)</p></details> |
| **[Software is infrastructure: failures, successes, costs, and the case for formal verification](https://arxiv.org/abs/2506.13821v4)** | 2026-01-29 | <details><summary>Show</summary><p>In this chapter we outline the role that software has in modern society, along with the staggering costs of poor software quality. To lay this bare, we recall the costs of some of the major software failures that happened during the last 40 years. We argue that these costs justify researching, studying and applying formal software verification and in particular program analysis. This position is supported by successful industrial experiences.</p></details> |  |
| **[Formal Verification of Noisy Quantum Reinforcement Learning Policies](https://arxiv.org/abs/2512.01502v2)** | 2026-01-29 | <details><summary>Show</summary><p>Quantum reinforcement learning (QRL) aims to use quantum effects to create sequential decision-making policies that achieve tasks more effectively than their classical counterparts. However, QRL policies face uncertainty from quantum measurements and hardware noise, such as bit-flip, phase-flip, and depolarizing errors, which can lead to unsafe behavior. Existing work offers no systematic way to verify whether trained QRL policies meet safety requirements under specific noise conditions. We introduce QVerifier, a formal verification method that applies probabilistic model checking to analyze trained QRL policies with and without modeled quantum noise. QVerifier builds a complete model of the policy-environment interaction, incorporates quantum uncertainty directly into the transition probabilities, and then checks safety properties using the Storm model checker. Experiments across multiple QRL environments show that QVerifier precisely measures how different noise models influence safety, revealing both performance degradation and cases where noise can help. By enabling rigorous safety verification before deployment, QVerifier addresses a critical need: because access to quantum hardware is expensive, pre-deployment verification is essential for any safety-critical use of QRL. QVerifier targets a potential sweet spot between classical and quantum computation, where trained QRL policies could still be modeled classically for probabilistic model checking. When the policy was trained under matching noise conditions, this formal model is exact; when trained on physical hardware, it constitutes an idealized approximation, as unknown hardware noise prevents exact policy modeling.</p></details> |  |
| **[User-Centric Evidence Ranking for Attribution and Fact Verification](https://arxiv.org/abs/2601.21387v1)** | 2026-01-29 | <details><summary>Show</summary><p>Attribution and fact verification are critical challenges in natural language processing for assessing information reliability. While automated systems and Large Language Models (LLMs) aim to retrieve and select concise evidence to support or refute claims, they often present users with either insufficient or overly redundant information, leading to inefficient and error-prone verification. To address this, we propose Evidence Ranking, a novel task that prioritizes presenting sufficient information as early as possible in a ranked list. This minimizes user reading effort while still making all available evidence accessible for sequential verification. We compare two approaches for the new ranking task: one-shot ranking and incremental ranking. We introduce a new evaluation framework, inspired by information retrieval metrics, and construct a unified benchmark by aggregating existing fact verification datasets. Extensive experiments with diverse models show that incremental ranking strategies better capture complementary evidence and that LLM-based methods outperform shallower baselines, while still facing challenges in balancing sufficiency and redundancy. Compared to evidence selection, we conduct a controlled user study and demonstrate that evidence ranking both reduces reading effort and improves verification. This work provides a foundational step toward more interpretable, efficient, and user-aligned information verification systems.</p></details> | EACL 2026 |
| **[SecIC3: Customizing IC3 for Hardware Security Verification](https://arxiv.org/abs/2601.21353v1)** | 2026-01-29 | <details><summary>Show</summary><p>Recent years have seen significant advances in using formal verification to check hardware security properties. Of particular practical interest are checking confidentiality and integrity of secrets, by checking that there is no information flow between the secrets and observable outputs. A standard method for checking information flow is to translate the corresponding non-interference hyperproperty into a safety property on a self-composition of the design, which has two copies of the design composed together. Although prior efforts have aimed to reduce the size of the self-composed design, there are no state-of-the-art model checkers that exploit their special structure for hardware security verification. In this paper, we propose SecIC3, a hardware model checking algorithm based on IC3 that is customized to exploit this self-composition structure. SecIC3 utilizes this structure in two complementary techniques: symmetric state exploration and adding equivalence predicates. We implement SecIC3 on top of two open-source IC3 implementations and evaluate it on a non-interference checking benchmark consisting of 10 designs. The experiment results show that SecIC3 significantly reduces the time for finding security proofs, with up to 49.3x proof speedup compared to baseline implementations.</p></details> | <details><summary>Accep...</summary><p>Accepted by DATE 2026</p></details> |
| **[Neural Theorem Proving for Verification Conditions: A Real-World Benchmark](https://arxiv.org/abs/2601.18944v2)** | 2026-01-28 | <details><summary>Show</summary><p>Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.</p></details> | Accepted in ICLR'26 |
| **[PalmBridge: A Plug-and-Play Feature Alignment Framework for Open-Set Palmprint Verification](https://arxiv.org/abs/2601.20351v1)** | 2026-01-28 | <details><summary>Show</summary><p>Palmprint recognition is widely used in biometric systems, yet real-world performance often degrades due to feature distribution shifts caused by heterogeneous deployment conditions. Most deep palmprint models assume a closed and stationary distribution, leading to overfitting to dataset-specific textures rather than learning domain-invariant representations. Although data augmentation is commonly used to mitigate this issue, it assumes augmented samples can approximate the target deployment distribution, an assumption that often fails under significant domain mismatch. To address this limitation, we propose PalmBridge, a plug-and-play feature-space alignment framework for open-set palmprint verification based on vector quantization. Rather than relying solely on data-level augmentation, PalmBridge learns a compact set of representative vectors directly from training features. During enrollment and verification, each feature vector is mapped to its nearest representative vector under a minimum-distance criterion, and the mapped vector is then blended with the original vector. This design suppresses nuisance variation induced by domain shifts while retaining discriminative identity cues. The representative vectors are jointly optimized with the backbone network using task supervision, a feature-consistency objective, and an orthogonality regularization term to form a stable and well-structured shared embedding space. Furthermore, we analyze feature-to-representative mappings via assignment consistency and collision rate to assess model's sensitivity to blending weights. Experiments on multiple palmprint datasets and backbone architectures show that PalmBridge consistently reduces EER in intra-dataset open-set evaluation and improves cross-dataset generalization with negligible to modest runtime overhead.</p></details> |  |
| **[Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2601.20221v1)** | 2026-01-28 | <details><summary>Show</summary><p>Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning trace verification, existing methods face two limitations: they produce only scalar reward values without explicit justification, and they rely on single-pass retrieval that precludes adaptive knowledge access as verification unfolds. We introduce $\method$, an agentic framework that addresses these limitations by training medical reasoning verifiers to iteratively query external medical corpora during evaluation. Our approach combines tool-augmented verification with an iterative reinforcement learning paradigm that requires only trace-level supervision, alongside an adaptive curriculum mechanism that dynamically adjusts training data distribution. Across four medical reasoning benchmarks, $\method$ achieves substantial gains over existing methods, improving MedQA accuracy by 23.5% and MedXpertQA by 32.0% relative to the base generator in particular. Crucially, $\method$ demonstrates an $\mathbf{8\times}$ reduction in sampling budget requirement compared to prior reward model baselines. These findings establish that grounding verification in dynamically retrieved evidence offers a principled path toward more reliable medical reasoning systems.</p></details> |  |
| **[Learn and Verify: A Framework for Rigorous Verification of Physics-Informed Neural Networks](https://arxiv.org/abs/2601.19818v1)** | 2026-01-27 | <details><summary>Show</summary><p>The numerical solution of differential equations using neural networks has become a central topic in scientific computing, with Physics-Informed Neural Networks (PINNs) emerging as a powerful paradigm for both forward and inverse problems. However, unlike classical numerical methods that offer established convergence guarantees, neural network-based approximations typically lack rigorous error bounds. Furthermore, the non-deterministic nature of their optimization makes it difficult to mathematically certify their accuracy. To address these challenges, we propose a "Learn and Verify" framework that provides computable, mathematically rigorous error bounds for the solutions of differential equations. By combining a novel Doubly Smoothed Maximum (DSM) loss for training with interval arithmetic for verification, we compute rigorous a posteriori error bounds as machine-verifiable proofs. Numerical experiments on nonlinear Ordinary Differential Equations (ODEs), including problems with time-varying coefficients and finite-time blow-up, demonstrate that the proposed framework successfully constructs rigorous enclosures of the true solutions, establishing a foundation for trustworthy scientific machine learning.</p></details> | 13 pages, 10 figures |
| **[Veri-Sure: A Contract-Aware Multi-Agent Framework with Temporal Tracing and Formal Verification for Correct RTL Code Generation](https://arxiv.org/abs/2601.19747v1)** | 2026-01-27 | <details><summary>Show</summary><p>In the rapidly evolving field of Electronic Design Automation (EDA), the deployment of Large Language Models (LLMs) for Register-Transfer Level (RTL) design has emerged as a promising direction. However, silicon-grade correctness remains bottlenecked by: (i) limited test coverage and reliability of simulation-centric evaluation, (ii) regressions and repair hallucinations introduced by iterative debugging, and (iii) semantic drift as intent is reinterpreted across agent handoffs. In this work, we propose Veri-Sure, a multi-agent framework that establishes a design contract to align agents' intent and uses a patching mechanism guided by static dependency slicing to perform precise, localized repairs. By integrating a multi-branch verification pipeline that combines trace-driven temporal analysis with formal verification consisting of assertion-based checking and boolean equivalence proofs, Veri-Sure enables functional correctness beyond pure simulations. We also introduce VerilogEval-v2-EXT, extending the original benchmark with 53 more industrial-grade design tasks and stratified difficulty levels, and show that Veri-Sure achieves state-of-the-art verified-correct RTL code generation performance, surpassing standalone LLMs and prior agentic systems.</p></details> |  |
| **[Hyperbolic Additive Margin Softmax with Hierarchical Information for Speaker Verification](https://arxiv.org/abs/2601.19709v1)** | 2026-01-27 | <details><summary>Show</summary><p>Speaker embedding learning based on Euclidean space has achieved significant progress, but it is still insufficient in modeling hierarchical information within speaker features. Hyperbolic space, with its negative curvature geometric properties, can efficiently represent hierarchical information within a finite volume, making it more suitable for the feature distribution of speaker embeddings. In this paper, we propose Hyperbolic Softmax (H-Softmax) and Hyperbolic Additive Margin Softmax (HAM-Softmax) based on hyperbolic space. H-Softmax incorporates hierarchical information into speaker embeddings by projecting embeddings and speaker centers into hyperbolic space and computing hyperbolic distances. HAM-Softmax further enhances inter-class separability by introducing margin constraint on this basis. Experimental results show that H-Softmax and HAM-Softmax achieve average relative EER reductions of 27.84% and 14.23% compared with standard Softmax and AM-Softmax, respectively, demonstrating that the proposed methods effectively improve speaker verification performance and at the same time preserve the capability of hierarchical structure modeling. The code will be released at https://github.com/PunkMale/HAM-Softmax.</p></details> | <details><summary>5 pag...</summary><p>5 pages, 3 figures, Accepted at ICASSP 2026</p></details> |
| **[DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing](https://arxiv.org/abs/2510.15303v4)** | 2026-01-27 | <details><summary>Show</summary><p>Large web-scale datasets have driven the rapid advancement of pre-trained language models (PLMs), but unauthorized data usage has raised serious copyright concerns. Existing dataset ownership verification (DOV) methods typically assume that watermarks remain stable during inference; however, this assumption often fails under natural noise and adversary-crafted perturbations. We propose the first certified dataset ownership verification method for PLMs under a gray-box setting (i.e., the defender can only query the suspicious model but is aware of its input representation module), based on dual-space smoothing (i.e., DSSmoothing). To address the challenges of text discreteness and semantic sensitivity, DSSmoothing introduces continuous perturbations in the embedding space to capture semantic robustness and applies controlled token reordering in the permutation space to capture sequential robustness. DSSmoothing consists of two stages: in the first stage, triggers are collaboratively embedded in both spaces to generate norm-constrained and robust watermarked datasets; in the second stage, randomized smoothing is applied in both spaces during verification to compute the watermark robustness (WR) of suspicious models and statistically compare it with the principal probability (PP) values of a set of benign models. Theoretically, DSSmoothing provides provable robustness guarantees for dataset ownership verification by ensuring that WR consistently exceeds PP under bounded dual-space perturbations. Extensive experiments on multiple representative web datasets demonstrate that DSSmoothing achieves stable and reliable verification performance and exhibits robustness against potential adaptive attacks. Our code is available at https://github.com/NcepuQiaoTing/DSSmoothing.</p></details> | <details><summary>To ap...</summary><p>To appear in WWW 2026. 12 pages</p></details> |
| **[DV-VLN: Dual Verification for Reliable LLM-Based Vision-and-Language Navigation](https://arxiv.org/abs/2601.18492v1)** | 2026-01-26 | <details><summary>Show</summary><p>Vision-and-Language Navigation (VLN) requires an embodied agent to navigate in a complex 3D environment according to natural language instructions. Recent progress in large language models (LLMs) has enabled language-driven navigation with improved interpretability. However, most LLM-based agents still rely on single-shot action decisions, where the model must choose one option from noisy, textualized multi-perspective observations. Due to local mismatches and imperfect intermediate reasoning, such decisions can easily deviate from the correct path, leading to error accumulation and reduced reliability in unseen environments. In this paper, we propose DV-VLN, a new VLN framework that follows a generate-then-verify paradigm. DV-VLN first performs parameter-efficient in-domain adaptation of an open-source LLaMA-2 backbone to produce a structured navigational chain-of-thought, and then verifies candidate actions with two complementary channels: True-False Verification (TFV) and Masked-Entity Verification (MEV). DV-VLN selects actions by aggregating verification successes across multiple samples, yielding interpretable scores for reranking. Experiments on R2R, RxR (English subset), and REVERIE show that DV-VLN consistently improves over direct prediction and sampling-only baselines, achieving competitive performance among language-only VLN agents and promising results compared with several cross-modal systems.Code is available at https://github.com/PlumJun/DV-VLN.</p></details> |  |
| **[V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering](https://arxiv.org/abs/2601.18240v1)** | 2026-01-26 | <details><summary>Show</summary><p>Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.</p></details> |  |
| **[Visual Attention Reasoning via Hierarchical Search and Self-Verification](https://arxiv.org/abs/2510.18619v4)** | 2026-01-26 | <details><summary>Show</summary><p>Multimodal Large Language Models (MLLMs) frequently hallucinate due to their reliance on fragile, linear reasoning and weak visual grounding. We propose Visual Attention Reasoning (VAR), a reinforcement learning framework that reformulates reasoning as a hierarchical search with self-verification. VAR enforces traceable evidence grounding by generating explicit bounding boxes, guided by a novel reward function combining geometric precision and semantic sufficiency. Furthermore, it replaces linear Chain-of-Thought with a tree-search policy capable of backtracking to correct logical errors. Theoretical analysis validates the framework's reliability, and extensive experiments demonstrate that VAR significantly outperforms state-of-the-art methods on complex hallucination and safety benchmarks.</p></details> | <details><summary>The p...</summary><p>The paper is withdrawn by the authors after discovering a flaw in the theoretical derivation presented in the Method section. This incorrect step leads to conclusions that are not supported by the corrected derivation. The authors plan to reconstruct the argument and will release an updated version once the issue is fully resolved</p></details> |
| **[Neuro-Symbolic Verification on Instruction Following of LLMs](https://arxiv.org/abs/2601.17789v1)** | 2026-01-25 | <details><summary>Show</summary><p>A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training.</p></details> |  |
| **[Spoofing-Aware Speaker Verification via Wavelet Prompt Tuning and Multi-Model Ensembles](https://arxiv.org/abs/2601.17557v1)** | 2026-01-24 | <details><summary>Show</summary><p>This paper describes the UZH-CL system submitted to the SASV section of the WildSpoof 2026 challenge. The challenge focuses on the integrated defense against generative spoofing attacks by requiring the simultaneous verification of speaker identity and audio authenticity. We proposed a cascaded Spoofing-Aware Speaker Verification framework that integrates a Wavelet Prompt-Tuned XLSR-AASIST countermeasure with a multi-model ensemble. The ASV component utilizes the ResNet34, ResNet293, and WavLM-ECAPA-TDNN architectures, with Z-score normalization followed by score averaging. Trained on VoxCeleb2 and SpoofCeleb, the system obtained a Macro a-DCF of 0.2017 and a SASV EER of 2.08%. While the system achieved a 0.16% EER in spoof detection on the in-domain data, results on unseen datasets, such as the ASVspoof5, highlight the critical challenge of cross-domain generalization.</p></details> | <details><summary>Syste...</summary><p>System description of the T03 team in the WildSpoof Challenge at ICASSP 2026</p></details> |
| **[Beyond Outcome Verification: Verifiable Process Reward Models for Structured Reasoning](https://arxiv.org/abs/2601.17223v1)** | 2026-01-23 | <details><summary>Show</summary><p>Recent work on reinforcement learning with verifiable rewards (RLVR) has shown that large language models (LLMs) can be substantially improved using outcome-level verification signals, such as unit tests for code or exact-match checks for mathematics. In parallel, process supervision has long been explored as a way to shape the intermediate reasoning behaviour of LLMs, but existing approaches rely on neural judges to score chain-of-thought steps, leaving them vulnerable to opacity, bias, and reward hacking. To address this gap, we introduce Verifiable Process Reward Models (VPRMs), a reinforcement-learning framework in which intermediate reasoning steps are checked by deterministic, rule-based verifiers. We apply VPRMs to risk-of-bias assessment for medical evidence synthesis, a domain where guideline-defined criteria and rule-based decision paths enable programmatic verification of reasoning traces. Across multiple datasets, we find that VPRMs generate reasoning that adheres closely to domain rules and achieve substantially higher coherence between step-level decisions and final labels. Results show that VPRMs achieve up to 20% higher F1 than state-of-the-art models and 6.5% higher than verifiable outcome rewards, with substantial gains in evidence grounding and logical coherence.</p></details> |  |
| **[StealthMark: Harmless and Stealthy Ownership Verification for Medical Segmentation via Uncertainty-Guided Backdoors](https://arxiv.org/abs/2601.17107v1)** | 2026-01-23 | <details><summary>Show</summary><p>Annotating medical data for training AI models is often costly and limited due to the shortage of specialists with relevant clinical expertise. This challenge is further compounded by privacy and ethical concerns associated with sensitive patient information. As a result, well-trained medical segmentation models on private datasets constitute valuable intellectual property requiring robust protection mechanisms. Existing model protection techniques primarily focus on classification and generative tasks, while segmentation models-crucial to medical image analysis-remain largely underexplored. In this paper, we propose a novel, stealthy, and harmless method, StealthMark, for verifying the ownership of medical segmentation models under black-box conditions. Our approach subtly modulates model uncertainty without altering the final segmentation outputs, thereby preserving the model's performance. To enable ownership verification, we incorporate model-agnostic explanation methods, e.g. LIME, to extract feature attributions from the model outputs. Under specific triggering conditions, these explanations reveal a distinct and verifiable watermark. We further design the watermark as a QR code to facilitate robust and recognizable ownership claims. We conducted extensive experiments across four medical imaging datasets and five mainstream segmentation models. The results demonstrate the effectiveness, stealthiness, and harmlessness of our method on the original model's segmentation performance. For example, when applied to the SAM model, StealthMark consistently achieved ASR above 95% across various datasets while maintaining less than a 1% drop in Dice and AUC scores, significantly outperforming backdoor-based watermarking methods and highlighting its strong potential for practical deployment. Our implementation code is made available at: https://github.com/Qinkaiyu/StealthMark.</p></details> | <details><summary>15 pa...</summary><p>15 pages,7 figures. Accepted to IEEE Transactions on Image Processing (TIP) 2026</p></details> |
| **[Preventing the Collapse of Peer Review Requires Verification-First AI](https://arxiv.org/abs/2601.16909v1)** | 2026-01-23 | <details><summary>Show</summary><p>This paper argues that AI-assisted peer review should be verification-first rather than review-mimicking. We propose truth-coupling, i.e. how tightly venue scores track latent scientific truth, as the right objective for review tools. We formalize two forces that drive a phase transition toward proxy-sovereign evaluation: verification pressure, when claims outpace verification capacity, and signal shrinkage, when real improvements become hard to separate from noise. In a minimal model that mixes occasional high-fidelity checks with frequent proxy judgment, we derive an explicit coupling law and an incentive-collapse condition under which rational effort shifts from truth-seeking to proxy optimization, even when current decisions still appear reliable. These results motivate actions for tool builders and program chairs: deploy AI as an adversarial auditor that generates auditable verification artifacts and expands effective verification bandwidth, rather than as a score predictor that amplifies claim inflation.</p></details> |  |
| **[Toward Practical Deductive Verification: Insights from a Qualitative Survey in Industry and Academia](https://arxiv.org/abs/2510.20514v2)** | 2026-01-23 | <details><summary>Show</summary><p>Deductive verification is an effective method to ensure that a given system exposes the intended behavior. In spite of its proven usefulness and feasibility in selected projects, deductive verification is still not a mainstream technique. To pave the way to widespread use, we present a study investigating the factors enabling successful applications of deductive verification and the underlying issues preventing broader adoption. We conducted semi-structured interviews with 30 practitioners of verification from both industry and academia and systematically analyzed the collected data employing a thematic analysis approach. Beside empirically confirming familiar challenges, e.g., the high level of expertise needed for conducting formal proofs, our data reveal several underexplored obstacles, such as proof maintenance, insufficient control over automation, and usability concerns. We further use the results from our data analysis to extract enablers and barriers for deductive verification and formulate concrete recommendations for practitioners, tool builders, and researchers, including principles for usability, automation, and integration with existing workflows.</p></details> |  |
| **[Inference-Time Scaling of Verification: Self-Evolving Deep Research Agents via Test-Time Rubric-Guided Verification](https://arxiv.org/abs/2601.15808v1)** | 2026-01-22 | <details><summary>Show</summary><p>Recent advances in Deep Research Agents (DRAs) are transforming automated knowledge discovery and problem-solving. While the majority of existing efforts focus on enhancing policy capabilities via post-training, we propose an alternative paradigm: self-evolving the agent's ability by iteratively verifying the policy model's outputs, guided by meticulously crafted rubrics. This approach gives rise to the inference-time scaling of verification, wherein an agent self-improves by evaluating its generated answers to produce iterative feedback and refinements. We derive the rubrics based on an automatically constructed DRA Failure Taxonomy, which systematically classifies agent failures into five major categories and thirteen sub-categories. We present DeepVerifier, a rubrics-based outcome reward verifier that leverages the asymmetry of verification and outperforms vanilla agent-as-judge and LLM judge baselines by 12%-48% in meta-evaluation F1 score. To enable practical self-evolution, DeepVerifier integrates as a plug-and-play module during test-time inference. The verifier produces detailed rubric-based feedback, which is fed back to the agent for iterative bootstrapping, refining responses without additional training. This test-time scaling delivers 8%-11% accuracy gains on challenging subsets of GAIA and XBench-DeepResearch when powered by capable closed-source LLMs. Finally, to support open-source advancement, we release DeepVerifier-4K, a curated supervised fine-tuning dataset of 4,646 high-quality agent steps focused on DRA verification. These examples emphasize reflection and self-critique, enabling open models to develop robust verification capabilities.</p></details> |  |
| **[MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification](https://arxiv.org/abs/2601.15498v1)** | 2026-01-21 | <details><summary>Show</summary><p>Speculative Decoding (SD) accelerates autoregressive large language model (LLM) inference by decoupling generation and verification. While recent methods improve draft quality by tightly coupling the drafter with the target model, the verification mechanism itself remains largely unchanged, relying on strict token-level rejection sampling. In practice, modern LLMs frequently operate in low-margin regimes where the target model exhibits weak preference among top candidates. In such cases, rejecting plausible runner-up tokens yields negligible information gain while incurring substantial rollback cost, leading to a fundamental inefficiency in verification. We propose Margin-Aware Speculative Verification, a training-free and domain-agnostic verification strategy that adapts to the target model's local decisiveness. Our method conditions verification on decision stability measured directly from the target logits and relaxes rejection only when strict verification provides minimal benefit. Importantly, the approach modifies only the verification rule and is fully compatible with existing target-coupled speculative decoding frameworks. Extensive experiments across model scales ranging from 8B to 235B demonstrate that our method delivers consistent and significant inference speedups over state-of-the-art baselines while preserving generation quality across diverse benchmarks.</p></details> | 11 pages, 5 figures |
| **[NP-Hard Lower Bound Complexity for Semantic Self-Verification](https://arxiv.org/abs/2501.15446v2)** | 2026-01-21 | <details><summary>Show</summary><p>We model Semantic Self-Verification (SSV) as the problem of determining whether a statement accurately characterizes its own semantic properties within a given interpretive framework that formalizes a challenge in AI safety and fairness: can an AI system verify that it has correctly interpreted rules intended to govern its behavior? We prove that SSV, in this specification, is NP-complete by constructing a polynomial-time reduction from 3-Satisfiability (3-SAT). Our reduction maps a 3-SAT formula to an instance of SSV involving ambiguous terms with binary interpretations and semantic constraints derived from logical clauses. This establishes that even simplified forms of semantic self-verification should face computational barriers. The NP-complete lower bound has implications for AI safety and fairness approaches that rely on semantic interpretation of instructions, including but not limited to constitutional AI, alignment via natural language, and instruction-following systems. Approaches where an AI system verify its understanding of directives may face this computational barrier. We argue that more realistic verification scenarios likely face even greater complexity.</p></details> | EACL 2026 |
| **[V-CAGE: Context-Aware Generation and Verification for Scalable Long-Horizon Embodied Tasks](https://arxiv.org/abs/2601.15164v1)** | 2026-01-21 | <details><summary>Show</summary><p>Learning long-horizon embodied behaviors from synthetic data remains challenging because generated scenes are often physically implausible, language-driven programs frequently "succeed" without satisfying task semantics, and high-level instructions require grounding into executable action sequences. To address these limitations, we introduce V-CAGE, a closed-loop framework for generating robust, semantically aligned manipulation datasets at scale. First, we propose a context-aware instantiation mechanism that enforces geometric consistency during scene synthesis. By dynamically maintaining a map of prohibited spatial areas as objects are placed, our system prevents interpenetration and ensures reachable, conflict-free configurations in cluttered environments. Second, to bridge the gap between abstract intent and low-level control, we employ a hierarchical instruction decomposition module. This decomposes high-level goals (e.g., "get ready for work") into compositional action primitives, facilitating coherent long-horizon planning. Crucially, we enforce semantic correctness through a VLM-based verification loop. Acting as a visual critic, the VLM performs rigorous rejection sampling after each subtask, filtering out "silent failures" where code executes but fails to achieve the visual goal. Experiments demonstrate that V-CAGE yields datasets with superior physical and semantic fidelity, significantly boosting the success rate and generalization of downstream policies compared to non-verified baselines.</p></details> |  |
| **[AI, Metacognition, and the Verification Bottleneck: A Three-Wave Longitudinal Study of Human Problem-Solving](https://arxiv.org/abs/2601.17055v1)** | 2026-01-21 | <details><summary>Show</summary><p>This longitudinal pilot study tracked how generative AI reshapes problem-solving over six months across three waves in an academic setting. AI integration reached saturation by Wave 3, with daily use rising from 52.4% to 95.7% and ChatGPT adoption from 85.7% to 100%. A dominant hybrid workflow increased 2.7-fold, adopted by 39.1% of participants. The verification paradox emerged: participants relied most heavily on AI for difficult tasks (73.9%) yet showed declining verification confidence (68.1%) where performance was worst (47.8% accuracy on complex tasks). Objective performance declined systematically: 95.2% to 81.0% to 66.7% to 47.8% across problem difficulty, with belief-performance gaps widening to 34.6 percentage points. This indicates a fundamental shift where verification, not solution generation, became the bottleneck in human-AI problem-solving. The ACTIVE Framework synthesizes findings grounded in cognitive load theory: Awareness and task-AI alignment, Critical verification protocols, Transparent human-in-the-loop integration, Iterative skill development countering cognitive offloading, Verification confidence calibration, and Ethical evaluation. The authors provide implementation pathways for institutions and practitioners. Key limitations include sample homogeneity (academic cohort only, convenience sampling) limiting generalizability to corporate, clinical, or regulated professional contexts; self-report bias in confidence measures (32.2 percentage point divergence from objective performance); lack of control conditions; restriction to mathematical/analytical problems; and insufficient timeframe to assess long-term skill trajectories. Results generalize primarily to early-adopter, academically affiliated populations. Causal validation requires randomized controlled trials.</p></details> | <details><summary>62 pa...</summary><p>62 pages, 2 figures, 23 tables</p></details> |
| **[Robust Verification of Concurrent Stochastic Games](https://arxiv.org/abs/2601.12003v2)** | 2026-01-21 | <details><summary>Show</summary><p>Autonomous systems often operate in multi-agent settings and need to make concurrent, strategic decisions, typically in uncertain environments. Verification and control problems for these systems can be tackled with concurrent stochastic games (CSGs), but this model requires transition probabilities to be precisely specified - an unrealistic requirement in many real-world settings. We introduce *robust CSGs* and their subclass *interval CSGs* (ICSGs), which capture epistemic uncertainty about transition probabilities in CSGs. We propose a novel framework for *robust* verification of these models under worst-case assumptions about transition uncertainty. Specifically, we develop the underlying theoretical foundations and efficient algorithms, for finite- and infinite-horizon objectives in both zero-sum and nonzero-sum settings, the latter based on (social-welfare optimal) Nash equilibria. We build an implementation in the PRISM-games model checker and demonstrate the feasibility of robust verification of ICSGs across a selection of large benchmarks.</p></details> | <details><summary>Exten...</summary><p>Extended version of a paper accepted to TACAS 2026. Main text: 17 pages, 2 figures, 2 tables; Appendix: 37 pages, 3 figures, 3 tables. Minor revisions and clarifications to the appendix; no changes to results</p></details> |
| **[ClaimDB: A Fact Verification Benchmark over Large Structured Data](https://arxiv.org/abs/2601.14698v1)** | 2026-01-21 | <details><summary>Show</summary><p>Despite substantial progress in fact-verification benchmarks, claims grounded in large-scale structured data remain underexplored. In this work, we introduce ClaimDB, the first fact-verification benchmark where the evidence for claims is derived from compositions of millions of records and multiple tables. ClaimDB consists of 80 unique real-life databases covering a wide range of domains, from governance and healthcare to media, education and the natural sciences. At this scale, verification approaches that rely on "reading" the evidence break down, forcing a timely shift toward reasoning in executable programs. We conduct extensive experiments with 30 state-of-the-art proprietary and open-source (below 70B) LLMs and find that none exceed 83% accuracy, with more than half below 55%. Our analysis also reveals that both closed- and open-source models struggle with abstention -- the ability to admit that there is no evidence to decide -- raising doubts about their reliability in high-stakes data analysis. We release the benchmark, code, and the LLM leaderboard at https://claimdb.github.io .</p></details> | <details><summary>The d...</summary><p>The data, code, and leaderboard are available at https://claimdb.github.io</p></details> |
| **[DAME: Duration-Aware Matryoshka Embedding for Duration-Robust Speaker Verification](https://arxiv.org/abs/2601.13999v1)** | 2026-01-20 | <details><summary>Show</summary><p>Short-utterance speaker verification remains challenging due to limited speaker-discriminative cues in short speech segments. While existing methods focus on enhancing speaker encoders, the embedding learning strategy still forces a single fixed-dimensional representation reused for utterances of any length, leaving capacity misaligned with the information available at different durations. We propose Duration-Aware Matryoshka Embedding (DAME), a model-agnostic framework that builds a nested hierarchy of sub-embeddings aligned to utterance durations: lower-dimensional representations capture compact speaker traits from short utterances, while higher dimensions encode richer details from longer speech. DAME supports both training from scratch and fine-tuning, and serves as a direct alternative to conventional large-margin fine-tuning, consistently improving performance across durations. On the VoxCeleb1-O/E/H and VOiCES evaluation sets, DAME consistently reduces the equal error rate on 1-s and other short-duration trials, while maintaining full-length performance with no additional inference cost. These gains generalize across various speaker encoder architectures under both general training and fine-tuning setups.</p></details> | <details><summary>5 pag...</summary><p>5 pages, 2 figures, Accepted at ICASSP 2026</p></details> |
| **[The CAISAR Platform: Extending the Reach of Machine Learning Specification and Verification](https://arxiv.org/abs/2506.12084v2)** | 2026-01-20 | <details><summary>Show</summary><p>The formal specification and verification of machine learning programs saw remarkable progress in less than a decade, leading to a profusion of tools. However, diversity may lead to fragmentation, resulting in tools that are difficult to compare, except for very specific benchmarks. Furthermore, this progress is heavily geared towards the specification and verification of a certain class of property, that is, local robustness properties. But while provers are becoming more and more efficient at solving local robustness properties, even slightly more complex properties, involving multiple neural networks for example, cannot be expressed in the input languages of winners of the International Competition of Verification of Neural Networks VNN-Comp. In this tool paper, we present CAISAR, an open-source platform dedicated to machine learning specification and verification. We present its specification language, suitable for modelling complex properties on neural networks, support vector machines and boosted trees. We show on concrete use-cases how specifications written in this language are automatically translated to queries to state-of-the-art provers, notably by using automated graph editing techniques, making it possible to use their off-the-shelf versions. The artifact to reproduce the paper claims is available at the following DOI: https://doi.org/10.5281/zenodo.15209510</p></details> |  |
| **[Foundational VeriFast: Pragmatic Certification of Verification Tool Results through Hinted Mirroring](https://arxiv.org/abs/2601.13727v1)** | 2026-01-20 | <details><summary>Show</summary><p>VeriFast is a leading tool for the modular formal verification of correctness properties of single-threaded and multi-threaded C and Rust programs. It verifies a program by symbolically executing each function in isolation, exploiting user-annotated preconditions, postconditions, and loop invariants written in a form of separation logic, and using a separation logic-based symbolic representation of memory. However, the tool itself, written in roughly 30K lines of OCaml code, has not been formally verified. Therefore, bugs in the tool could cause it to falsely report the correctness of the input program. We here report on an early result extending VeriFast to emit, upon successful verification of a Rust program, a Rocq proof script that proves correctness of the program with respect to a Rocq-encoded axiomatic semantics of Rust. This significantly enhances VeriFast's applicability in safety-critical domains. We apply hinted mirroring: we record key information from VeriFast's symbolic execution run, and use it to direct a replay of the run in Rocq.</p></details> | 8 pages, 2 figures |
| **[GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark](https://arxiv.org/abs/2601.13711v1)** | 2026-01-20 | <details><summary>Show</summary><p>Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.</p></details> |  |
| **[Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification](https://arxiv.org/abs/2601.13589v1)** | 2026-01-20 | <details><summary>Show</summary><p>This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.</p></details> |  |
| **[Multi-Stage Verification-Centric Framework for Mitigating Hallucination in Multi-Modal RAG](https://arxiv.org/abs/2507.20136v2)** | 2026-01-20 | <details><summary>Show</summary><p>This paper presents the technical solution developed by team CRUISE for the KDD Cup 2025 Meta Comprehensive RAG Benchmark for Multi-modal, Multi-turn (CRAG-MM) challenge. The challenge aims to address a critical limitation of modern Vision Language Models (VLMs): their propensity to hallucinate, especially when faced with egocentric imagery, long-tail entities, and complex, multi-hop questions. This issue is particularly problematic in real-world applications where users pose fact-seeking queries that demand high factual accuracy across diverse modalities. To tackle this, we propose a robust, multi-stage framework that prioritizes factual accuracy and truthfulness over completeness. Our solution integrates a lightweight query router for efficiency, a query-aware retrieval and summarization pipeline, a dual-pathways generation and a post-hoc verification. This conservative strategy is designed to minimize hallucinations, which incur a severe penalty in the competition's scoring metric. Our approach achieved 3rd place in Task 1, demonstrating the effectiveness of prioritizing answer reliability in complex multi-modal RAG systems. Our implementation is available at https://github.com/Breezelled/KDD-Cup-2025-Meta-CRAG-MM .</p></details> | <details><summary>KDD C...</summary><p>KDD Cup 2025 Meta CRAG-MM Challenge: Third Prize in the Single-Source Augmentation Task</p></details> |
| **[The Achilles' Heel of Angular Margins: A Chebyshev Polynomial Fix for Speaker Verification](https://arxiv.org/abs/2601.13198v1)** | 2026-01-19 | <details><summary>Show</summary><p>Angular margin losses, such as AAM-Softmax, have become the de facto in speaker and face verification. Their success hinges on directly manipulating the angle between features and class prototypes. However, this manipulation relies on the arccos function to recover the angle, introducing a significant yet overlooked source of training instability. The derivative of arccos explodes at its boundaries, causing gradient peaks during optimisation. Furthermore, the formulation fails to generate a sufficiently sharp gradient for hard-to-classify examples. We address these issues by proposing ChebyAAM, a loss that replaces the arccos operation with its Chebyshev polynomial approximation. This substitution eliminates gradient explosion and applies a stronger corrective signal to hard examples, leading to more effective optimisation. Experiments on three benchmarks (VoxCeleb, SITW, and CN-Celeb) demonstrate that our method resolves the instability and consistently improves performance. Our work suggests that approximating angular operations, rather than calculating them explicitly, offers a more robust path for designing future metric learning losses. Code is available at https://github.com/ExtraOrdinaryLab/vibe.</p></details> | <details><summary>Accep...</summary><p>Accepted for presentation at ICASSP 2026</p></details> |
| **[Human Emotion Verification by Action Languages via Answer Set Programming](https://arxiv.org/abs/2601.12912v1)** | 2026-01-19 | <details><summary>Show</summary><p>In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).</p></details> | <details><summary>Under...</summary><p>Under consideration in Theory and Practice of Logic Programming (TPLP)</p></details> |
| **[Automatic Generation of Formal Specification and Verification Annotations Using LLMs and Test Oracles](https://arxiv.org/abs/2601.12845v1)** | 2026-01-19 | <details><summary>Show</summary><p>Recent verification tools aim to make formal verification more accessible to software engineers by automating most of the verification process. However, annotating conventional programs with the formal specification and verification constructs (preconditions, postconditions, loop invariants, auxiliary predicates and functions and proof helpers) required to prove their correctness still demands significant manual effort and expertise. This paper investigates how LLMs can automatically generate such annotations for programs written in Dafny, a verification-aware programming language, starting from conventional code accompanied by natural language specifications (in comments) and test code. In experiments on 110 Dafny programs, a multimodel approach combining Claude Opus 4.5 and GPT-5.2 generated correct annotations for 98.2% of the programs within at most 8 repair iterations, using verifier feedback. A logistic regression analysis shows that proof-helper annotations contribute disproportionately to problem difficulty for current LLMs. Assertions in the test cases served as static oracles to automatically validate the generated pre/postconditions. We also compare generated and manual solutions and present an extension for Visual Studio Code to incorporate automatic generation into the IDE, with encouraging usability feedback.</p></details> |  |
| **[VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension](https://arxiv.org/abs/2601.12781v1)** | 2026-01-19 | <details><summary>Show</summary><p>Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.</p></details> |  |
| **[Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits](https://arxiv.org/abs/2601.11924v1)** | 2026-01-17 | <details><summary>Show</summary><p>We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $Γ$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $φ$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $Γ$ can translate into an effective corruption level ranging from $Γ$ to $NΓ$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(Γ)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $Ω(Γ)$ penalty and a high-corruption regime $Γ=Θ(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $ν$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $Γ$.</p></details> |  |
| **[Diffusion-Driven Deceptive Patches: Adversarial Manipulation and Forensic Detection in Facial Identity Verification](https://arxiv.org/abs/2601.09806v1)** | 2026-01-14 | <details><summary>Show</summary><p>This work presents an end-to-end pipeline for generating, refining, and evaluating adversarial patches to compromise facial biometric systems, with applications in forensic analysis and security testing. We utilize FGSM to generate adversarial noise targeting an identity classifier and employ a diffusion model with reverse diffusion to enhance imperceptibility through Gaussian smoothing and adaptive brightness correction, thereby facilitating synthetic adversarial patch evasion. The refined patch is applied to facial images to test its ability to evade recognition systems while maintaining natural visual characteristics. A Vision Transformer (ViT)-GPT2 model generates captions to provide a semantic description of a person's identity for adversarial images, supporting forensic interpretation and documentation for identity evasion and recognition attacks. The pipeline evaluates changes in identity classification, captioning results, and vulnerabilities in facial identity verification and expression recognition under adversarial conditions. We further demonstrate effective detection and analysis of adversarial patches and adversarial samples using perceptual hashing and segmentation, achieving an SSIM of 0.95.</p></details> | <details><summary>This ...</summary><p>This manuscript is a preprint. A revised version of this work has been accepted for publication in the Springer Nature book Artificial Intelligence-Driven Forensics. This version includes one additional figure for completeness</p></details> |
| **[Forward Symbolic Execution for Trustworthy Automation of Binary Code Verification](https://arxiv.org/abs/2304.08848v2)** | 2026-01-13 | <details><summary>Show</summary><p>Control flow in unstructured programs can be complex and dynamic, which makes static analysis difficult. Yet, automated reasoning about unstructured control flow is important when certifying properties of binary (machine) code in trustworthy systems, e.g., cryptographic routines. We present a theory of forward symbolic execution for unstructured programs suitable for use in theorem provers that enables automated verification of both functional and non-functional program properties. The theory's foundation is a set of inference rules where each member corresponds to an operation in a symbolic execution engine. The rules are designed to give control over the tradeoff between the preservation of precision and introduction of overapproximation. We instantiate our theory for BIR, a previously proposed intermediate language for binary analysis. We demonstrate how symbolic executors can be constructed for BIR with common optimizations such as pruning of infeasible symbolic states. We implemented our theory in the HOL4 theorem prover using the HolBA binary analysis library, obtaining machine-checked proofs of soundness of symbolic execution for BIR. We practically evaluated two applications of our theory: verification of functional properties of RISC-V binaries and verification of execution time bounds of programs running on the ARM Cortex-M0 processor. The evaluation shows that such verification can be automated with moderate overhead on medium-sized programs.</p></details> |  |
| **[MultiCheck: Strengthening Web Trust with Unified Multimodal Fact Verification](https://arxiv.org/abs/2508.05097v3)** | 2026-01-13 | <details><summary>Show</summary><p>Misinformation on the web increasingly appears in multimodal forms, combining text, images, and OCR-rendered content in ways that amplify harm to public trust and vulnerable communities. While prior fact-checking systems often rely on unimodal signals or shallow fusion strategies, modern misinformation campaigns operate across modalities and require models that can reason over subtle cross-modal inconsistencies in a transparent and responsible manner. We introduce MultiCheck, a lightweight and interpretable framework for multimodal fact verification that jointly analyzes textual, visual, and OCR evidence. At its core, MultiCheck employs a relational fusion module based on element-wise difference and product operations, allowing for explicit cross-modal interaction modeling with minimal computational overhead. A contrastive alignment objective further helps the model distinguish between supporting and refuting evidence while maintaining a small memory and energy footprint, making it suitable for low-resource deployment. Evaluated on the Factify-2 (5-class) and Mocheg (3-class) benchmarks, MultiCheck achieves huge performance improvement and remains robust under noisy OCR and missing modality conditions. Its efficiency, transparency, and real-world robustness make it well-suited for journalists, civil society organisations, and web integrity efforts working to build a safer and more trustworthy web.</p></details> |  |
| **[Decentralized Firmware Integrity Verification for Cyber-Physical Systems Using Ethereum Blockchain](https://arxiv.org/abs/2601.08091v1)** | 2026-01-13 | <details><summary>Show</summary><p>Firmware integrity is a foundational requirement for securing Cyber-Physical Systems (CPS), where malicious or compromised firmware can result in persistent backdoors, unauthorized control, or catastrophic system failures. Traditional verification mechanisms such as secure boot, digital signatures, and centralized hash databases are increasingly inadequate due to risks from insider threats and single points of failure. In this paper, we propose a decentralized firmware integrity verification framework built on the Ethereum blockchain, offering tamperproof, transparent, and trustless validation. Our system stores SHA-256 hashes of firmware binaries within smart contracts deployed on the Ethereum Sepolia testnet, using Web3 and Infura for seamless on-chain interaction. A Python-based client tool computes firmware hashes and communicates with the blockchain to register and verify firmware authenticity in realtime. We implement and evaluate a fully functional prototype using real firmware samples, demonstrating successful contract deployment, hash registration, and integrity verification through live blockchain transactions. Experimental results confirm the reliability and low cost (in gas fees) of our approach, highlighting its practicality and scalability for real-world CPS applications. To enhance scalability and performance, we discuss extensions using Layer-2 rollups and off-chain storage via the InterPlanetary File System (IPFS). We also outline integration pathways with secure boot mechanisms, Trusted Platform Module (TPM)based attestation, and zero-trust architectures. This work contributes a practical and extensible model for blockchain-based firmware verification, significantly strengthening the defense against firmware tampering and supply chain attacks in critical CPS environments.</p></details> | <details><summary>6 pag...</summary><p>6 pages, 6 figures, 3 tables</p></details> |
| **[Towards Automating Blockchain Consensus Verification with IsabeLLM](https://arxiv.org/abs/2601.07654v1)** | 2026-01-12 | <details><summary>Show</summary><p>Consensus protocols are crucial for a blockchain system as they are what allow agreement between the system's nodes in a potentially adversarial environment. For this reason, it is paramount to ensure their correct design and implementation to prevent such adversaries from carrying out malicious behaviour. Formal verification allows us to ensure the correctness of such protocols, but requires high levels of effort and expertise to carry out and thus is often omitted in the development process. In this paper, we present IsabeLLM, a tool that integrates the proof assistant Isabelle with a Large Language Model to assist and automate proofs. We demonstrate the effectiveness of IsabeLLM by using it to develop a novel model of Bitcoin's Proof of Work consensus protocol and verify its correctness. We use the DeepSeek R1 API for this demonstration and found that we were able to generate correct proofs for each of the non-trivial lemmas present in the verification.</p></details> |  |
| **[Proof-Carrying Verification for ReLU Networks via Rational Certificates](https://arxiv.org/abs/2512.24339v2)** | 2026-01-12 | <details><summary>Show</summary><p>Rectified Linear Unit (ReLU) networks are piecewise-linear (PWL), so universal linear safety properties can be reduced to reasoning about linear constraints. Modern verifiers rely on SMT(LRA) procedures or MILP encodings, but a safety claim is only as trustworthy as the evidence it produces. We develop a proof-carrying verification core for PWL neural constraints on an input domain $D \subseteq \mathbb{R}^n$. We formalize the exact PWL semantics as a union of polyhedra indexed by activation patterns, relate this model to standard exact SMT/MILP encodings and to the canonical convex-hull (ideal) relaxation of a bounded ReLU, and introduce a small certificate calculus whose proof objects live over $\mathbb{Q}$. Two certificate types suffice for the core reasoning steps: entailment certificates validate linear consequences (bound tightening and learned cuts), while Farkas certificates prove infeasibility of strengthened counterexample queries (branch-and-bound pruning). We give an exact proof kernel that checks these artifacts in rational arithmetic, prove soundness and completeness for linear entailment, and show that infeasibility certificates admit sparse representatives depending only on dimension. Worked examples illustrate end-to-end certified reasoning without trusting the solver beyond its exported witnesses.</p></details> |  |
| **[Machine Learning Model Trading with Verification under Information Asymmetry](https://arxiv.org/abs/2601.07510v1)** | 2026-01-12 | <details><summary>Show</summary><p>Machine learning (ML) model trading, known for its role in protecting data privacy, faces a major challenge: information asymmetry. This issue can lead to model deception, a problem that current literature has not fully solved, where the seller misrepresents model performance to earn more. We propose a game-theoretic approach, adding a verification step in the ML model market that lets buyers check model quality before buying. However, this method can be expensive and offers imperfect information, making it harder for buyers to decide. Our analysis reveals that a seller might probabilistically conduct model deception considering the chance of model verification. This deception probability decreases with the verification accuracy and increases with the verification cost. To maximize seller payoff, we further design optimal pricing schemes accounting for heterogeneous buyers' strategic behaviors. Interestingly, we find that reducing information asymmetry benefits both the seller and buyer. Meanwhile, protecting buyer order information doesn't improve the payoff for the buyer or the seller. These findings highlight the importance of reducing information asymmetry in ML model trading and open new directions for future research.</p></details> | <details><summary>Accep...</summary><p>Accepted in IEEE TRANSACTIONS ON NETWORKING 2025</p></details> |
| **[FROAV: A Framework for RAG Observation and Agent Verification -- Lowering the Barrier to LLM Agent Research](https://arxiv.org/abs/2601.07504v1)** | 2026-01-12 | <details><summary>Show</summary><p>The rapid advancement of Large Language Models (LLMs) and their integration into autonomous agent systems has created unprecedented opportunities for document analysis, decision support, and knowledge retrieval. However, the complexity of developing, evaluating, and iterating on LLM-based agent workflows presents significant barriers to researchers, particularly those without extensive software engineering expertise. We present FROAV (Framework for RAG Observation and Agent Verification), an open-source research platform that democratizes LLM agent research by providing a plug-and-play architecture combining visual workflow orchestration, a comprehensive evaluation framework, and extensible Python integration. FROAV implements a multi-stage Retrieval-Augmented Generation (RAG) pipeline coupled with a rigorous "LLM-as-a-Judge" evaluation system, all accessible through intuitive graphical interfaces. Our framework integrates n8n for no-code workflow design, PostgreSQL for granular data management, FastAPI for flexible backend logic, and Streamlit for human-in-the-loop interaction. Through this integrated ecosystem, researchers can rapidly prototype RAG strategies, conduct prompt engineering experiments, validate agent performance against human judgments, and collect structured feedback-all without writing infrastructure code. We demonstrate the framework's utility through its application to financial document analysis, while emphasizing its material-agnostic architecture that adapts to any domain requiring semantic analysis. FROAV represents a significant step toward making LLM agent research accessible to a broader scientific community, enabling researchers to focus on hypothesis testing and algorithmic innovation rather than system integration challenges.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 1 figure, 3 tables</p></details> |
| **[SRAF: Stealthy and Robust Adversarial Fingerprint for Copyright Verification of Large Language Models](https://arxiv.org/abs/2505.06304v3)** | 2026-01-12 | <details><summary>Show</summary><p>The protection of Intellectual Property (IP) for Large Language Models (LLMs) has become a critical concern as model theft and unauthorized commercialization escalate. While adversarial fingerprinting offers a promising black-box solution for ownership verification, existing methods suffer from significant limitations: they are fragile against model modifications, sensitive to system prompt variations, and easily detectable due to high-perplexity input patterns. In this paper, we propose SRAF, which employs a multi-task adversarial optimization strategy that jointly optimizes fingerprints across homologous model variants and diverse chat templates, allowing the fingerprint to anchor onto invariant decision boundary features. Furthermore, we introduce a Perplexity Hiding technique that embeds adversarial perturbations within Markdown tables, effectively aligning the prompt's statistics with natural language to evade perplexity-based detection. Experiments on Llama-2 variants demonstrate SRAF's superior robustness and stealthiness compared to state-of-the-art baselines, offering a practical black-box solution for ownership verification.</p></details> |  |
| **[Standardization of Post-Publication Code Verification by Journals is Possible with the Support of the Community](https://arxiv.org/abs/2601.07189v1)** | 2026-01-12 | <details><summary>Show</summary><p>Reproducibility remains a challenge in machine learning research. While code and data availability requirements have become increasingly common, post-publication verification in journals is still limited and unformalized. This position paper argues that it is plausible for journals and conference proceedings to implement post-publication verification. We propose a modification to ACM pre-publication verification badges that allows independent researchers to submit post-publication code replications to the journal, leading to visible verification badges included in the article metadata. Each article may earn up to two badges, each linked to verified code in its corresponding public repository. We describe the motivation, related initiatives, a formal framework, the potential impact, possible limitations, and alternative views.</p></details> | 10 pages, 1 figure |

### CrossRef
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[A new mechanism for the formation of deposits induced by siloxane in internal combustion engines: Based on structural composition analysis of real samples and simulation verification](https://doi.org/10.1016/j.fuel.2026.138718)** | 2026-08-01 | <details><summary>Show</summary><p></p></details> | Fuel |
| **[Intelligent assembly conformance verification for complex products: A rotationally invariant multi-view visual framework](https://doi.org/10.1016/j.rcim.2026.103247)** | 2026-08-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Robot...</summary><p>Robotics and Computer-Integrated Manufacturing</p></details> |
| **[Spatiotemporal perception and motion similarity learning for real-time assembly verification](https://doi.org/10.1016/j.rcim.2026.103258)** | 2026-08-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Robot...</summary><p>Robotics and Computer-Integrated Manufacturing</p></details> |
| **[AI3D: Multimodal verification system against projective attacks for deep learning classifiers](https://doi.org/10.1016/j.patcog.2025.113036)** | 2026-07-01 | <details><summary>Show</summary><p></p></details> | Pattern Recognition |
| **[Gender-independent kinship verification network via fuzzy disentangling and multi-metric inference](https://doi.org/10.1016/j.neunet.2026.108691)** | 2026-07-01 | <details><summary>Show</summary><p></p></details> | Neural Networks |
| **[Design and experimental verification of capsule propellant enabling multiple controllable delayed ignitions](https://doi.org/10.1016/j.fuel.2026.138477)** | 2026-07-01 | <details><summary>Show</summary><p></p></details> | Fuel |
| **[281Security verification of authenticated encryption with associated data under chosen message attack assumption using Tamarin prover](https://doi.org/10.1515/9783111436548-013)** | 2026-06-20 | <details><summary>Show</summary><p></p></details> | Cybersecurity |
| **[Design and verification of self-facilitation card-based toolset for complex problem-solving](https://doi.org/10.1016/j.tsc.2026.102130)** | 2026-06-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Think...</summary><p>Thinking Skills and Creativity</p></details> |
| **[Impact dynamics of graded cellular projectiles on clamped circular plates: A coupling analysis theory and verification](https://doi.org/10.1016/j.ijimpeng.2026.105641)** | 2026-06-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Inter...</summary><p>International Journal of Impact Engineering</p></details> |
| **[Design and verification of a tunable ceramics metamaterial and measurement of its sensing performance](https://doi.org/10.1016/j.jtice.2026.106647)** | 2026-06-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Journ...</summary><p>Journal of the Taiwan Institute of Chemical Engineers</p></details> |
| **[Formal verification of time-bounded BPMN model with message broker using timed automata](https://doi.org/10.1016/j.sasc.2026.200453)** | 2026-06-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Syste...</summary><p>Systems and Soft Computing</p></details> |
| **[Enhanced metamodeling strategy for uncertainty quantification and reliability verification in heterogeneous connected and automated vehicle platoon control models](https://doi.org/10.1016/j.ress.2025.112183)** | 2026-06-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Relia...</summary><p>Reliability Engineering &amp; System Safety</p></details> |
| **[Team collaboration-oriented multi-agent pathfinding and probabilistic verification](https://doi.org/10.1016/j.inffus.2026.104125)** | 2026-06-01 | <details><summary>Show</summary><p></p></details> | Information Fusion |
| **[In-situ self-sensing method for magnetically controlled friction of magnetorheological elastomers and experimental verification](https://doi.org/10.1016/j.triboint.2026.111693)** | 2026-06-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Tribo...</summary><p>Tribology International</p></details> |
| **[Robust opacity in timed automata: notions and verification](https://doi.org/10.1016/j.ress.2025.112093)** | 2026-06-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Relia...</summary><p>Reliability Engineering &amp; System Safety</p></details> |
| **[Student engagement with ChatGPT for educational tasks: Effects of inoculation training on verification intentions and behavior](https://doi.org/10.1016/j.caeo.2026.100335)** | 2026-06-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Compu...</summary><p>Computers and Education Open</p></details> |
| **[Development and verification of a new fission gas release model for large-grained UO2 pellets](https://doi.org/10.1016/j.anucene.2026.112148)** | 2026-06-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Annal...</summary><p>Annals of Nuclear Energy</p></details> |
| **[Blockchain-Enhanced Maritime Education Ecosystem: Decentralized Credentialing for Global Seafarer Competency Verification](https://doi.org/10.64123/mijm.v2.i1.2)** | 2026-05-31 | <details><summary>Show</summary><p>The global maritime industry faces a critical seafarer shortage of 89,510 officers, exacerbated by fragmented credential verification systems, fraudulent certification practices, and inefficient competency recognition across jurisdictions. This research develops a comprehensive Blockchain-Enhanced Maritime Education Ecosystem integrating decentralized credentialing infrastructure with IoT-enabled simulation training and economic impact assessment of maritime labor market transformation. Through qualitative analysis incorporating perspectives from maritime education experts, certification authority administrators, and shipping company training managers, this study identifies critical requirements for trustless verification systems, interoperability standards, and stakeholder adoption barriers. The framework synthesizes educational technology innovations with maritime training regulatory compliance, demonstrating how blockchain-based credentialing can simultaneously enhance seafarer mobility, reduce certification fraud, and improve competency verification efficiency while addressing cybersecurity concerns and digital divide challenges. Findings reveal significant gaps in current certification systems, particularly regarding cross-jurisdictional recognition mechanisms and real-time competency tracking capabilities. The research contributes actionable implementation pathways for maritime stakeholders globally, offering evidence-based strategies for digital transformation of seafarer credentialing aligned with STCW Convention requirements and SDG 4 (Quality Education), while addressing the urgent workforce development needs essential for maritime industry sustainability and operational safety.</p></details> | <details><summary>Multi...</summary><p>Multicore International Journal of Multidisciplinary (MIJM)</p></details> |
| **[System dynamics-based dynamic evaluation of value synergy and effectiveness verification of governance strategies for urban water conservancy projects](https://doi.org/10.1016/j.eswa.2026.131208)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Exper...</summary><p>Expert Systems with Applications</p></details> |
| **[Comprehensive analysis and experimental verification of the role of mitochondrial dynamics-related genes in liver hepatocellular carcinoma](https://doi.org/10.1016/j.gendis.2025.101872)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | Genes &amp; Diseases |
| **[HMT-SUV: Hierarchical multi-sensor tracking with single-source uncertainty verification for resolving target existence ambiguity](https://doi.org/10.1016/j.eswa.2026.131297)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Exper...</summary><p>Expert Systems with Applications</p></details> |
| **[Physics-informed sparse reinforcement learning for hybrid VTOL UAV control: HILS verification and tethered hover benchmarking](https://doi.org/10.1016/j.ast.2026.111646)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Aeros...</summary><p>Aerospace Science and Technology</p></details> |
| **[LAAS-KM: Lightweight authentication with aggregate signature verification and key management protocol for VANETs](https://doi.org/10.1016/j.pmcj.2026.102183)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Perva...</summary><p>Pervasive and Mobile Computing</p></details> |
| **[Experimental Verification of Finite Element Modeling for ICT-Type DC High-Voltage Power Supply](https://doi.org/10.1109/tasc.2025.3644828)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>IEEE ...</summary><p>IEEE Transactions on Applied Superconductivity</p></details> |
| **[“If you agree with me, it must be true”: Social verification creates shared reality and consolidates impressions](https://doi.org/10.1016/j.jesp.2026.104887)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Journ...</summary><p>Journal of Experimental Social Psychology</p></details> |
| **[Crash consistency in an NVM-enabled hybrid storage system: Problems, solutions, and verification](https://doi.org/10.1016/j.sysarc.2026.103705)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Journ...</summary><p>Journal of Systems Architecture</p></details> |
| **[Mitigating cracks in high-speed metro frog nose rails: Profile optimization with field verification](https://doi.org/10.1016/j.engfailanal.2026.110627)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Engin...</summary><p>Engineering Failure Analysis</p></details> |
| **[AGentVLM: Access control policy generation and verification framework with language models](https://doi.org/10.1016/j.jisa.2026.104379)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Journ...</summary><p>Journal of Information Security and Applications</p></details> |
| **[A time domain compound attention neural network for direction perception with vestibular model verification](https://doi.org/10.1016/j.eswa.2026.131186)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Exper...</summary><p>Expert Systems with Applications</p></details> |
| **[Elucidating the material basis and mechanism of Shegan Mahuang decoction in inhibiting influenza virus pneumonia based on UHPLC-HRMS, network pharmacology and experimental verification](https://doi.org/10.1016/j.jep.2026.121332)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Journ...</summary><p>Journal of Ethnopharmacology</p></details> |
| **[FPGA-based optimization of communication encoding and verification of eliminating modulation phase for phasemeter in space gravitational wave detection](https://doi.org/10.1016/j.optcom.2026.132872)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Optic...</summary><p>Optics Communications</p></details> |
| **[Experimental verification and theoretical study on nonlinear vibrations of aluminum-based sandwich airfoil plate under external excitations](https://doi.org/10.1016/j.euromechsol.2025.105994)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Europ...</summary><p>European Journal of Mechanics - A/Solids</p></details> |
| **[G²SQL: guided &amp; guarded Text-to-SQL generation with two-stage verification](https://doi.org/10.1016/j.eswa.2026.131276)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Exper...</summary><p>Expert Systems with Applications</p></details> |
| **[Safety-assured decision support for ASV navigation via hybrid graph planning and timed automata verification](https://doi.org/10.1016/j.eswa.2026.131367)** | 2026-05-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Exper...</summary><p>Expert Systems with Applications</p></details> |
| **[Performance analysis of ionoacoustic signal reconstruction algorithms for proton-beam range verification in heterogeneous medium](https://doi.org/10.1117/12.3085522)** | 2026-04-03 | <details><summary>Show</summary><p></p></details> | <details><summary>Medic...</summary><p>Medical Imaging 2026: Ultrasonic Imaging and Tomography</p></details> |
| **[Tissue-specific bioaccumulation risk of fluorinated liquid crystal monomers with high nAtom and complex structure in zebrafish: An in-silico simulation and experimental verification](https://doi.org/10.1016/j.jece.2026.121161)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Journ...</summary><p>Journal of Environmental Chemical Engineering</p></details> |
| **[Identification of PI3K gene family in large yellow croaker (Larimichthys crocea): Expression patterns under Pseudomonas plecoglossicida infection and hypoxia stress, and functional verification of pik3r3b](https://doi.org/10.1016/j.fsi.2026.111199)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Fish ...</summary><p>Fish &amp; Shellfish Immunology</p></details> |
| **[GanFinger: GAN-Based Fingerprint Generation for Deep Neural Network Ownership Verification](https://doi.org/10.26599/tst.2025.9010028)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Tsing...</summary><p>Tsinghua Science and Technology</p></details> |
| **[Scattering of SV waves by the canyon topography: Numerical analysis and shaking table test verification](https://doi.org/10.1016/j.compgeo.2025.107767)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Compu...</summary><p>Computers and Geotechnics</p></details> |
| **[Elemental fingerprinting and regional verification of Pakistani basmati and non-basmati rice varieties using ICP-MS and multivariate analysis](https://doi.org/10.1016/j.foodchem.2026.148075)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | Food Chemistry |
| **[Design and verification of the double door system for fusion reactor remote maintenance casks](https://doi.org/10.1016/j.fusengdes.2026.115655)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Fusio...</summary><p>Fusion Engineering and Design</p></details> |
| **[Adaptive synchronous sliding mode levelling system for combine harvester considering track circumference: Co-simulation and experimental verification](https://doi.org/10.1016/j.biosystemseng.2026.104396)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Biosy...</summary><p>Biosystems Engineering</p></details> |
| **[New insights into opacity verification in timed discrete-event systems](https://doi.org/10.1016/j.automatica.2026.112869)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | Automatica |
| **[Optimizing a detection system for fissile material in nuclear disarmament verification](https://doi.org/10.1016/j.nima.2025.171237)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Nucle...</summary><p>Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment</p></details> |
| **[Toward robust replay attack detection in Automatic Speaker Verification: A study of spectrum estimation and channel magnitude response modeling](https://doi.org/10.1016/j.csl.2025.101906)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Compu...</summary><p>Computer Speech &amp; Language</p></details> |
| **[The design, modeling, and performance verification of an integrated PEMFC-powered engine for UAVs](https://doi.org/10.1016/j.apenergy.2026.127465)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | Applied Energy |
| **[Design and verification of a microbial consortium with an anchoring-interface enhancement strategy for efficient PAHs degradation in groundwater](https://doi.org/10.1016/j.watres.2026.125439)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | Water Research |
| **[Corrigendum to "Verification of PWR-Core power distribution based on precisely calculated SPND response currents" &lt;[ Nuclear Engineering and Design 448 (2026) 114726]&gt;](https://doi.org/10.1016/j.nucengdes.2026.114804)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Nucle...</summary><p>Nuclear Engineering and Design</p></details> |
| **[Chemistry and feasibility verification of β-hemihydrate phosphogypsum in silico-aluminophosphate geopolymer](https://doi.org/10.1016/j.susmat.2025.e01811)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Susta...</summary><p>Sustainable Materials and Technologies</p></details> |
| **[Intrinsic, Cu-, Ag-, and Au-modified Janus NbSSe for detection of SF6 decomposition harmful gases: DFT calculations and gas-sensing mechanism verification](https://doi.org/10.1016/j.jece.2026.121331)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Journ...</summary><p>Journal of Environmental Chemical Engineering</p></details> |
| **[Reliability verification methods for artificial intelligence components in instrumentation and control systems at nuclear power plants](https://doi.org/10.1016/j.net.2025.104096)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Nucle...</summary><p>Nuclear Engineering and Technology</p></details> |
| **[EqBaB: Efficient equivalence verification for compressed DNNs with bound propagation](https://doi.org/10.1016/j.neucom.2026.132791)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | Neurocomputing |
| **[Temporal and spacetime topological states as experimental probes of IG-RUEQFT: An information-gauge interpretation and verification proposal](https://doi.org/10.1016/j.nexres.2026.101415)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | Next Research |
| **[Dynamic event-triggered stabilization of irregular output-constrained nonholonomic systems with experimental verification](https://doi.org/10.1016/j.conengprac.2026.106788)** | 2026-04-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Contr...</summary><p>Control Engineering Practice</p></details> |
| **[Building a microintegrated laser module with fiber coupling at 720nm: design, simulation, and verification](https://doi.org/10.1117/12.3080519)** | 2026-03-06 | <details><summary>Show</summary><p></p></details> | <details><summary>Optic...</summary><p>Optical Interconnects and Packaging 2026</p></details> |
| **[Equivalent test optical system (ETOS) concept for pre-assembly verification of optical working distance in GRIN rod lens probes](https://doi.org/10.1117/12.3106030)** | 2026-03-06 | <details><summary>Show</summary><p></p></details> | <details><summary>Photo...</summary><p>Photons Plus Ultrasound: Imaging and Sensing 2026</p></details> |
| **[Experimental and theoretical verification of structure–adsorption relationships in cage-based covalent organic frameworks for iodine capture](https://doi.org/10.1016/j.colsurfa.2025.139304)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Collo...</summary><p>Colloids and Surfaces A: Physicochemical and Engineering Aspects</p></details> |
| **[Analytical assurance of hydrogen purity: A comprehensive framework for trace contaminant verification and conformity assessment](https://doi.org/10.1016/j.ceja.2025.101015)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Chemi...</summary><p>Chemical Engineering Journal Advances</p></details> |
| **[Irreversible nitrite-oxidising bacteria inhibition by operational shutdowns for high‑ammonia wastewater treatment: from mechanism insights to pilot‑scale granular sludge reactor verification](https://doi.org/10.1016/j.biortech.2026.133930)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Biore...</summary><p>Bioresource Technology</p></details> |
| **[Multicenter verification and method comparison of the STANDARD M10 Influenza, RSV and SARS-CoV-2 assay in Amies medium](https://doi.org/10.1016/j.diagmicrobio.2025.117230)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Diagn...</summary><p>Diagnostic Microbiology and Infectious Disease</p></details> |
| **[A priori estimation of measurement uncertainty as a tool to improve verification of geometric product specifications with coordinate measuring machines](https://doi.org/10.1016/j.measurement.2025.120275)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | Measurement |
| **[B-PhishQR—A blockchain-based framework for secure QR code verification against phishing attacks](https://doi.org/10.1016/j.teler.2025.100289)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Telem...</summary><p>Telematics and Informatics Reports</p></details> |
| **[Characterizing the Experiment for Calibration with Uranium (Excalibur) neutron source for use in warhead verification](https://doi.org/10.1016/j.nima.2025.171071)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Nucle...</summary><p>Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment</p></details> |
| **[FedCkic: A federated learning inference attack defense method based on centralized key agreement and integrity verification](https://doi.org/10.1016/j.eswa.2025.130455)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Exper...</summary><p>Expert Systems with Applications</p></details> |
| **[Design and verification of an intelligent variable-stiffness vibration isolator for a high-resolution optical satellite based on machine learning](https://doi.org/10.1016/j.ast.2025.111553)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Aeros...</summary><p>Aerospace Science and Technology</p></details> |
| **[Evaluation of Soil Dynamic Properties Using Shake Table Tests on Laminar Shear Box and Its Numerical Verification](https://doi.org/10.1061/ijgnai.gmeng-12896)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Inter...</summary><p>International Journal of Geomechanics</p></details> |
| **[Highway Bridge Crack Inspection Verification and Training Using an Automated Augmented Reality System](https://doi.org/10.1061/jcemd4.coeng-17009)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Journ...</summary><p>Journal of Construction Engineering and Management</p></details> |
| **[Integrated network toxicology, molecular docking, molecular dynamics simulation, and experimental verification to elucidate the mechanism of hepatotoxicity and processing detoxification in Fructus Meliae Toosendan](https://doi.org/10.1016/j.toxicon.2025.108933)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | Toxicon |
| **[An advanced flexible dynamic model and experimental verification for armature assembly in servo valve](https://doi.org/10.1016/j.rineng.2025.108866)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Resul...</summary><p>Results in Engineering</p></details> |
| **[Automating appliance verification in facilities management using a denoised Voltage-Current feature extraction and classification pipeline](https://doi.org/10.1016/j.jii.2025.101040)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Journ...</summary><p>Journal of Industrial Information Integration</p></details> |
| **[Range verification of a 10C ion beam: Feasibility of Compton imaging of 718 keV gamma rays](https://doi.org/10.1016/j.nima.2025.171105)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Nucle...</summary><p>Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment</p></details> |
| **[Verification of the safety of pack-cooking methods for managing food allergies during disasters](https://doi.org/10.1016/j.meafoo.2025.100273)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | Measurement: Food |
| **[Efficient smart home message verification protocol based on Chebyshev chaotic mapping](https://doi.org/10.1016/j.comnet.2026.112033)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | Computer Networks |
| **[Retraction Notice to “Dosimetric verification of cancer patient's treatment plan using an anthropomorphic, 3D-printed phantom” [Appl. Radiat. Isotop. 191C (2023), 110490]](https://doi.org/10.1016/j.apradiso.2025.112302)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Appli...</summary><p>Applied Radiation and Isotopes</p></details> |
| **[Finite element implementation and performance verification of a hydro-mechanical coupling method for unsaturated loess](https://doi.org/10.1016/j.compgeo.2025.107787)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Compu...</summary><p>Computers and Geotechnics</p></details> |
| **[Misinformation detection with automatic fact-based news verification](https://doi.org/10.1016/j.ins.2025.122868)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | Information Sciences |
| **[Two-year remote sensing and ground verification: Estimating chlorophyll content in winter wheat using UAV multi-spectral imagery](https://doi.org/10.1016/j.aiia.2025.10.017)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Artif...</summary><p>Artificial Intelligence in Agriculture</p></details> |
| **[Design and experimental verification of an isolated voltage probe for the 2 kHz–30 MHz interval operating in live conditions](https://doi.org/10.1016/j.measurement.2025.119920)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | Measurement |
| **[Optimization design and experimental Verification of SiC-Based lattice sandwich modular thermal protection system](https://doi.org/10.1016/j.compositesa.2025.109502)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Compo...</summary><p>Composites Part A: Applied Science and Manufacturing</p></details> |
| **[Intelligent defensive driving for autonomous vehicles: Framework, strategy and verification](https://doi.org/10.1016/j.aap.2025.108355)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Accid...</summary><p>Accident Analysis &amp; Prevention</p></details> |
| **[EdgeBatch: Efficient Decentralized Batch Verification for Edge Data Integrity via Reputation-Aware Combination Selection](https://doi.org/10.1109/tmc.2025.3645025)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>IEEE ...</summary><p>IEEE Transactions on Mobile Computing</p></details> |
| **[Qualitative verification of the scattering enhancement effect by surface charge on submicron particles](https://doi.org/10.1016/j.optlastec.2025.114615)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Optic...</summary><p>Optics &amp; Laser Technology</p></details> |
| **[Verification of a hybrid kinetic-gyrokinetic model using the advanced semi-Lagrange code ssV](https://doi.org/10.1016/j.cpc.2025.109980)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Compu...</summary><p>Computer Physics Communications</p></details> |
| **[DPD simulation on the formation of polyamide thin-film membrane via interfacial polymerization and experimental verification](https://doi.org/10.1016/j.memsci.2025.125094)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Journ...</summary><p>Journal of Membrane Science</p></details> |
| **[Performance verification of a dual-range stretchable vertical graphene strain sensor for microstrain and large deformation monitoring](https://doi.org/10.1016/j.measurement.2025.120124)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | Measurement |
| **[Generative AI literacy: Scale development and its influence on privacy protection behaviors and information verification behaviors](https://doi.org/10.1016/j.telpol.2025.103117)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Telec...</summary><p>Telecommunications Policy</p></details> |
| **[The verification and validation of the coupled neutronics thermal-hydraulics code, MTRDYN, for steady-state condition of RSG-GAS reactor](https://doi.org/10.1016/j.nucengdes.2025.114746)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Nucle...</summary><p>Nuclear Engineering and Design</p></details> |
| **[Toward an automated cross-multimodal verification of mobile app bug fixes integrating user feedback, developer responses, changelogs, and UI visual analysis](https://doi.org/10.1016/j.infsof.2025.107996)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Infor...</summary><p>Information and Software Technology</p></details> |
| **[Multi-omics analysis and experimental verification reveal the role of dihydrocaffeic acid against 5-fluorouracil-induced intestinal mucositis](https://doi.org/10.1016/j.phymed.2026.157837)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | Phytomedicine |
| **[Fact in fragments: Deconstructing complex claims via LLM-based atomic fact extraction and verification](https://doi.org/10.1016/j.eswa.2025.130572)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Exper...</summary><p>Expert Systems with Applications</p></details> |
| **[Dosimetric verification of HDR vaginal cylinder applications using Gafchromic film and Monte Carlo simulation with a custom phantom](https://doi.org/10.1016/j.apradiso.2025.112399)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Appli...</summary><p>Applied Radiation and Isotopes</p></details> |
| **[Axial, volumetric and roundness performance verification of coordinate measuring machine (CMM) with comparative study utilizing two different stylus tip materials](https://doi.org/10.1016/j.measurement.2025.120072)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | Measurement |
| **[The novel DPP-IV inhibitory peptides derived from goat milk: Purification, identification, bioactivities verification in-vitro and in-vivo](https://doi.org/10.1016/j.foodres.2025.118274)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Food ...</summary><p>Food Research International</p></details> |
| **[Feasibility verification of prompt gamma activation imaging based on rotation modulation collimator](https://doi.org/10.1016/j.nima.2025.171166)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Nucle...</summary><p>Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment</p></details> |
| **[Mining of key genes involved in the sulforaphane biosynthetic pathway of moringa and cloning, expression, and functional verification of MoMYR1](https://doi.org/10.1016/j.ijbiomac.2026.150633)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Inter...</summary><p>International Journal of Biological Macromolecules</p></details> |
| **[Guided and knowledgeable multi-agent debate for fact verification](https://doi.org/10.1016/j.eswa.2025.130103)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Exper...</summary><p>Expert Systems with Applications</p></details> |
| **[Topological design of a continuous fiber composite structure and its experimental verification](https://doi.org/10.1016/j.engstruct.2025.122062)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Engin...</summary><p>Engineering Structures</p></details> |
| **[Verification of the esters-producing properties of Thermoascus aurantiacus QH-1 derived from low-temperature Daqu by multiomics](https://doi.org/10.1016/j.fm.2025.104946)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | Food Microbiology |
| **[A multiscale simulation framework for composite manufacturing process: Data transfer and experimental verification](https://doi.org/10.1016/j.jmapro.2026.01.063)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Journ...</summary><p>Journal of Manufacturing Processes</p></details> |
| **[Failure prediction and uncertainty verification of LiDAR thermoelectric coolers using Archimedes spiral loss-based domain generalization](https://doi.org/10.1016/j.ress.2025.111942)** | 2026-03-01 | <details><summary>Show</summary><p></p></details> | <details><summary>Relia...</summary><p>Reliability Engineering &amp; System Safety</p></details> |

